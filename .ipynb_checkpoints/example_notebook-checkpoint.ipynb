{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cf7fc5-47e8-4703-9f75-d746d4897d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DP Fine-tune, and deploy a custom LLM model using Secludy PII-Free Synthetic Text Replicas Algorithm from AWS Marketplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d17e79a-6729-4289-b07b-84fc3b54700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pre-requisitesÔÉÅ\n",
    "Note: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "\n",
    "Ensure that IAM role used has AmazonSageMakerFullAccess\n",
    "\n",
    "Some hands-on experience using Amazon SageMaker.\n",
    "\n",
    "To use this algorithm successfully, ensure that:\n",
    "\n",
    "Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used:\n",
    "\n",
    "aws-marketplace:ViewSubscriptions\n",
    "\n",
    "aws-marketplace:Unsubscribe\n",
    "\n",
    "aws-marketplace:Subscribe\n",
    "\n",
    "or your AWS account has a subscription to For Seller to update:Secludy PII-Free Synthetic Text Replicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eab5082-70d5-4890-b8a4-034b097da208",
   "metadata": {},
   "outputs": [],
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2941ca89-ef36-49aa-9f79-ac155912f235",
   "metadata": {},
   "source": [
    "To subscribe to the algorithm: \n",
    "1. Open the algorithm listing page For Seller to update:Secludy PII-Free Synthetic Text Replicas.\n",
    "2. On the AWS Marketplace listing, click on Continue to subscribe button.\n",
    "3. On the Subscribe to this software page, review and click on ‚ÄúAccept Offer‚Äù if you agree with EULA, pricing, and support terms.\n",
    "4. Once you click on Continue to configuration button and then choose a region, you will see a Product Arn. This is the algorithm ARN that you need to specify while training a custom ML model. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d715101b-4fe4-43c4-a56d-f750889e0cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_arn = \"<Customer to specify algorithm ARN corresponding to their AWS region>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5be185-dad6-4dd7-bdae-54e227f55eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5688a8e2-731c-44d8-93cd-bdfc1bd86602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/28/25 04:48:25] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1075\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1075</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/28/25 04:48:25]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=53940;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=528215;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1075\u001b\\\u001b[2m1075\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1075\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1075</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=401018;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=414853;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1075\u001b\\\u001b[2m1075\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sagemaker\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86d59966-3e56-4dd8-a415-533cab9200ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::992382599914:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a854dfa6-a7ee-4355-8b94-4b1c8473096b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/28/25 04:48:46] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1075\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1075</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/28/25 04:48:46]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=906899;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=705369;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1075\u001b\\\u001b[2m1075\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import boto3\n",
    "session = boto3.Session(region_name='us-east-1')\n",
    "sagemaker_session = sagemaker.Session(boto_session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c30f2385-6577-4f71-9d5f-3e519f20131e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-us-east-1-992382599914'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket = sagemaker_session.default_bucket()\n",
    "bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da57fc5-d3fd-47a5-95a3-2d42ece78a5b",
   "metadata": {},
   "source": [
    "# Buyer need to update S3 output location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "723621c9-7115-433e-bf1d-5dd6d335c37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_location = \"s3://{}/<For seller to Update:Update a unique prefix>/{}\".format(\n",
    "#     bucket, \"output\"\n",
    "# )\n",
    "output_location = \"s3://secludy-public-listing/prod listing out/buyer-test/\".format(\n",
    "    bucket, \"output\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f6377d-9670-42dd-be83-f5e1c0991764",
   "metadata": {},
   "source": [
    "# Define hyperparameters ,update the prompt tailer to your use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1375cd7b-041f-42bb-a86a-28098f697189",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hyperparameters = {  \n",
    "    \"epochs\": \"1\",\n",
    "        \"batch_size\": \"1\",\n",
    "        \"learning_rate\": \"0.001\",\n",
    "        \"grad_accum_steps\": \"16\",\n",
    "        \"epsilon\": \"8.0\",\n",
    "        \"max_seq_length\": \"512\",\n",
    "        \"instruction\": \"Classify the following email content into its appropriate category based on its content.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "463848fd-fa05-4d34-bfda-b4952bc86683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import AlgorithmEstimator\n",
    "estimator = AlgorithmEstimator(\n",
    "algorithm_arn='arn:aws:sagemaker:us-east-1:865070037744:algorithm/dp-synthetic-data-generation-v-30e04e08e851391b9f69a7bb0d8e2033',\n",
    "role=role,\n",
    "instance_count=1,\n",
    "instance_type='ml.g5.xlarge',\n",
    "sagemaker_session=sagemaker_session,\n",
    "   output_path = output_location,\n",
    "    hyperparameters=hyperparameters,\n",
    "base_job_name='privacy-protective-synthetic-data-generation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5adaa2-0ea7-49cb-9c34-ab1f0a26c71c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/28/25 06:16:39] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py#90\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">90</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/28/25 06:16:39]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=321432;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=667306;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py#90\u001b\\\u001b[2m90\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training-job with name:                                       <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#1042\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         privacy-protective-synthetic-data-gener-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-01-28-06-16-39-177        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training-job with name:                                       \u001b]8;id=456638;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=918632;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#1042\u001b\\\u001b[2m1042\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         privacy-protective-synthetic-data-gener-\u001b[1;36m2025\u001b[0m-01-28-06-16-39-177        \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-28 06:16:39 Starting - Starting the training job...\n",
      "..25-01-28 06:17:04 Starting - Preparing the instances for training.\n",
      "..25-01-28 06:17:35 Downloading - Downloading input data.\n",
      "................................................................................\n",
      ".\u001b[34mPython 3.10.16\u001b[0mning - Training image download completed. Training in progress..\n",
      "\u001b[34mPackage                 Version\u001b[0m\n",
      "\u001b[34m----------------------- ------------\u001b[0m\n",
      "\u001b[34mabsl-py                 2.1.0\u001b[0m\n",
      "\u001b[34maccelerate              1.3.0\u001b[0m\n",
      "\u001b[34maiohappyeyeballs        2.4.4\u001b[0m\n",
      "\u001b[34maiohttp                 3.11.11\u001b[0m\n",
      "\u001b[34maiosignal               1.3.2\u001b[0m\n",
      "\u001b[34mannotated-types         0.7.0\u001b[0m\n",
      "\u001b[34masync-timeout           5.0.1\u001b[0m\n",
      "\u001b[34mattrs                   24.3.0\u001b[0m\n",
      "\u001b[34mbitsandbytes            0.45.0\u001b[0m\n",
      "\u001b[34mcertifi                 2022.12.7\u001b[0m\n",
      "\u001b[34mcffi                    1.17.1\u001b[0m\n",
      "\u001b[34mcharset-normalizer      2.1.1\u001b[0m\n",
      "\u001b[34mclick                   8.1.8\u001b[0m\n",
      "\u001b[34mcryptography            44.0.0\u001b[0m\n",
      "\u001b[34mdatasets                3.2.0\u001b[0m\n",
      "\u001b[34mdill                    0.3.8\u001b[0m\n",
      "\u001b[34mdocker-pycreds          0.4.0\u001b[0m\n",
      "\u001b[34meinops                  0.8.0\u001b[0m\n",
      "\u001b[34mfilelock                3.13.1\u001b[0m\n",
      "\u001b[34mflash-attn              2.7.3\u001b[0m\n",
      "\u001b[34mfrozenlist              1.5.0\u001b[0m\n",
      "\u001b[34mfsspec                  2024.2.0\u001b[0m\n",
      "\u001b[34mgitdb                   4.0.12\u001b[0m\n",
      "\u001b[34mGitPython               3.1.44\u001b[0m\n",
      "\u001b[34mgrpcio                  1.69.0\u001b[0m\n",
      "\u001b[34mhuggingface-hub         0.27.1\u001b[0m\n",
      "\u001b[34midna                    3.4\u001b[0m\n",
      "\u001b[34mJinja2                  3.1.3\u001b[0m\n",
      "\u001b[34mMarkdown                3.7\u001b[0m\n",
      "\u001b[34mmarkdown-it-py          3.0.0\u001b[0m\n",
      "\u001b[34mMarkupSafe              2.1.5\u001b[0m\n",
      "\u001b[34mmdurl                   0.1.2\u001b[0m\n",
      "\u001b[34mmpmath                  1.3.0\u001b[0m\n",
      "\u001b[34mmultidict               6.1.0\u001b[0m\n",
      "\u001b[34mmultiprocess            0.70.16\u001b[0m\n",
      "\u001b[34mnetworkx                3.2.1\u001b[0m\n",
      "\u001b[34mnumpy                   1.26.3\u001b[0m\n",
      "\u001b[34mpackaging               24.2\u001b[0m\n",
      "\u001b[34mpandas                  2.2.3\u001b[0m\n",
      "\u001b[34mpeft                    0.14.0\u001b[0m\n",
      "\u001b[34mpillow                  10.2.0\u001b[0m\n",
      "\u001b[34mpip                     24.2\u001b[0m\n",
      "\u001b[34mplatformdirs            4.3.6\u001b[0m\n",
      "\u001b[34mpropcache               0.2.1\u001b[0m\n",
      "\u001b[34mprotobuf                5.29.3\u001b[0m\n",
      "\u001b[34mpsutil                  6.1.1\u001b[0m\n",
      "\u001b[34mpyarrow                 19.0.0\u001b[0m\n",
      "\u001b[34mpycparser               2.22\u001b[0m\n",
      "\u001b[34mpydantic                2.10.5\u001b[0m\n",
      "\u001b[34mpydantic_core           2.27.2\u001b[0m\n",
      "\u001b[34mPygments                2.19.1\u001b[0m\n",
      "\u001b[34mpython-dateutil         2.9.0.post0\u001b[0m\n",
      "\u001b[34mpython-dotenv           1.0.1\u001b[0m\n",
      "\u001b[34mpytz                    2024.2\u001b[0m\n",
      "\u001b[34mPyYAML                  6.0.2\u001b[0m\n",
      "\u001b[34mregex                   2024.11.6\u001b[0m\n",
      "\u001b[34mrequests                2.32.3\u001b[0m\n",
      "\u001b[34mrich                    13.9.4\u001b[0m\n",
      "\u001b[34msafetensors             0.5.2\u001b[0m\n",
      "\u001b[34mscipy                   1.15.1\u001b[0m\n",
      "\u001b[34msentencepiece           0.2.0\u001b[0m\n",
      "\u001b[34msentry-sdk              2.20.0\u001b[0m\n",
      "\u001b[34msetproctitle            1.3.4\u001b[0m\n",
      "\u001b[34msetuptools              75.1.0\u001b[0m\n",
      "\u001b[34msix                     1.17.0\u001b[0m\n",
      "\u001b[34msmmap                   5.0.2\u001b[0m\n",
      "\u001b[34msympy                   1.13.1\u001b[0m\n",
      "\u001b[34mtensorboard             2.18.0\u001b[0m\n",
      "\u001b[34mtensorboard-data-server 0.7.2\u001b[0m\n",
      "\u001b[34mtokenizers              0.21.0\u001b[0m\n",
      "\u001b[34mtorch                   2.1.1+cu121\u001b[0m\n",
      "\u001b[34mtorchaudio              2.1.1+cu121\u001b[0m\n",
      "\u001b[34mtorchvision             0.16.1+cu121\u001b[0m\n",
      "\u001b[34mtqdm                    4.67.1\u001b[0m\n",
      "\u001b[34mtransformers            4.48.1\u001b[0m\n",
      "\u001b[34mtriton                  2.1.0\u001b[0m\n",
      "\u001b[34mtrl                     0.13.0\u001b[0m\n",
      "\u001b[34mtyping_extensions       4.12.2\u001b[0m\n",
      "\u001b[34mtzdata                  2025.1\u001b[0m\n",
      "\u001b[34murllib3                 1.26.13\u001b[0m\n",
      "\u001b[34mwandb                   0.19.4\u001b[0m\n",
      "\u001b[34mWerkzeug                3.1.3\u001b[0m\n",
      "\u001b[34mwheel                   0.44.0\u001b[0m\n",
      "\u001b[34mxxhash                  3.5.0\u001b[0m\n",
      "\u001b[34myarl                    1.18.3\u001b[0m\n",
      "\u001b[34mStarting training...\u001b[0m\n",
      "\u001b[34mTraining data directory: /opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mModel directory: /opt/ml/model\u001b[0m\n",
      "\u001b[34mReloading base model with quantization...\u001b[0m\n",
      "\u001b[34m/opt/conda/envs/fast_dp_dev/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mLoading and processing dataset...\u001b[0m\n",
      "\u001b[34mFound 1 JSONL files in /opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mUsing instruction: Classify the following email content into its appropriate category based on its content.\u001b[0m\n",
      "\u001b[34mProcessing costco_emails_formatted.jsonl...\u001b[0m\n",
      "\u001b[34mTotal processed entries: 4660\u001b[0m\n",
      "\u001b[34mSplitting dataset...\u001b[0m\n",
      "\u001b[34mDataset sizes - Train: 3728, Validation: 932\u001b[0m\n",
      "\u001b[34m***** SINGLE RUN *****\u001b[0m\n",
      "\u001b[34m/opt/program/fast_dp_trainer.py:30: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `FastDPTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\u001b[0m\n",
      "\u001b[34m/opt/conda/envs/fast_dp_dev/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m#015Map:   0%|          | 0/3728 [00:00<?, ? examples/s]#015Map:  27%|‚ñà‚ñà‚ñã       | 1000/3728 [00:00<00:00, 5897.15 examples/s]#015Map:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2000/3728 [00:00<00:00, 6148.00 examples/s]#015Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3000/3728 [00:00<00:00, 6425.57 examples/s]#015Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3728/3728 [00:00<00:00, 6460.81 examples/s]#015Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3728/3728 [00:00<00:00, 6297.43 examples/s]\u001b[0m\n",
      "\u001b[34m#015Map:   0%|          | 0/932 [00:00<?, ? examples/s]#015Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 932/932 [00:00<00:00, 7005.63 examples/s]#015Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 932/932 [00:00<00:00, 6857.00 examples/s]\u001b[0m\n",
      "\u001b[34mStarting training...\u001b[0m\n",
      "\u001b[34mNumber of trainable components:  392 ; Number of trainable layers:  392\u001b[0m\n",
      "\u001b[34m>>>>>>>>>>>>>>>>> Applying  automatic  per-sample gradient clipping.\u001b[0m\n",
      "\u001b[34m>>>>>>>>>>>>>>>>> Block heads for per-sample gradient clipping are defined as: ['base_model.model.model.layers.0.self_attn.q_proj.lora_A.default']\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/233 [00:00<?, ?it/s]/opt/conda/envs/fast_dp_dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\u001b[0m\n",
      "\u001b[34m{'loss': 2.4009, 'grad_norm': 1.4098109006881714, 'learning_rate': 0.00014285714285714284, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34mStep 2: Loss = 2.4009\u001b[0m\n",
      "\u001b[34m{'loss': 2.3535, 'grad_norm': 1.3968547582626343, 'learning_rate': 0.0002857142857142857, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34mStep 3: Loss = 2.3535\u001b[0m\n",
      "\u001b[34m{'loss': 2.3974, 'grad_norm': 1.4039863348007202, 'learning_rate': 0.00042857142857142855, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34mStep 4: Loss = 2.3974\u001b[0m\n",
      "\u001b[34m{'loss': 2.3704, 'grad_norm': 1.4410611391067505, 'learning_rate': 0.0005714285714285714, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34mStep 5: Loss = 2.3704\u001b[0m\n",
      "\u001b[34m{'loss': 2.3283, 'grad_norm': 1.4178719520568848, 'learning_rate': 0.0007142857142857143, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34mStep 6: Loss = 2.3283\u001b[0m\n",
      "\u001b[34m{'loss': 2.3566, 'grad_norm': 1.4010244607925415, 'learning_rate': 0.0008571428571428571, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34mStep 7: Loss = 2.3566\u001b[0m\n",
      "\u001b[34m{'loss': 2.2792, 'grad_norm': 1.4975212812423706, 'learning_rate': 0.001, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34mStep 8: Loss = 2.2792\u001b[0m\n",
      "\u001b[34m{'loss': 2.2335, 'grad_norm': 1.4937913417816162, 'learning_rate': 0.000995575221238938, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34mStep 9: Loss = 2.2335\u001b[0m\n",
      "\u001b[34m{'loss': 2.2273, 'grad_norm': 1.5484271049499512, 'learning_rate': 0.000991150442477876, 'epoch': 0.04}\u001b[0m\n",
      "\u001b[34mStep 10: Loss = 2.2273\u001b[0m\n",
      "\u001b[34m{'loss': 2.1699, 'grad_norm': 1.6027448177337646, 'learning_rate': 0.000986725663716814, 'epoch': 0.04}\u001b[0m\n",
      "\u001b[34mStep 11: Loss = 2.1699\u001b[0m\n",
      "\u001b[34m{'loss': 2.1734, 'grad_norm': 1.72893226146698, 'learning_rate': 0.0009823008849557523, 'epoch': 0.05}\u001b[0m\n",
      "\u001b[34mStep 12: Loss = 2.1734\u001b[0m\n",
      "\u001b[34m{'loss': 2.115, 'grad_norm': 1.7969094514846802, 'learning_rate': 0.0009778761061946903, 'epoch': 0.05}\u001b[0m\n",
      "\u001b[34mStep 13: Loss = 2.1150\u001b[0m\n",
      "\u001b[34m{'loss': 2.0842, 'grad_norm': 1.7367030382156372, 'learning_rate': 0.0009734513274336283, 'epoch': 0.06}\u001b[0m\n",
      "\u001b[34mStep 14: Loss = 2.0842\u001b[0m\n",
      "\u001b[34m{'loss': 2.0217, 'grad_norm': 1.670121192932129, 'learning_rate': 0.0009690265486725664, 'epoch': 0.06}\u001b[0m\n",
      "\u001b[34mStep 15: Loss = 2.0217\u001b[0m\n",
      "\u001b[34m{'loss': 2.0046, 'grad_norm': 1.63031804561615, 'learning_rate': 0.0009646017699115044, 'epoch': 0.06}\u001b[0m\n",
      "\u001b[34mStep 16: Loss = 2.0046\u001b[0m\n",
      "\u001b[34m{'loss': 1.993, 'grad_norm': 1.540791630744934, 'learning_rate': 0.0009601769911504425, 'epoch': 0.07}\u001b[0m\n",
      "\u001b[34mStep 17: Loss = 1.9930\u001b[0m\n",
      "\u001b[34m{'loss': 1.9152, 'grad_norm': 1.4714925289154053, 'learning_rate': 0.0009557522123893806, 'epoch': 0.07}\u001b[0m\n",
      "\u001b[34mStep 18: Loss = 1.9152\u001b[0m\n",
      "\u001b[34m{'loss': 1.9054, 'grad_norm': 1.4581881761550903, 'learning_rate': 0.0009513274336283187, 'epoch': 0.08}\u001b[0m\n",
      "\u001b[34mStep 19: Loss = 1.9054\u001b[0m\n",
      "\u001b[34m{'loss': 1.8497, 'grad_norm': 1.420304298400879, 'learning_rate': 0.0009469026548672567, 'epoch': 0.08}\u001b[0m\n",
      "\u001b[34mStep 20: Loss = 1.8497\u001b[0m\n",
      "\u001b[34m{'loss': 1.8378, 'grad_norm': 1.363046407699585, 'learning_rate': 0.0009424778761061947, 'epoch': 0.09}\u001b[0m\n",
      "\u001b[34mStep 21: Loss = 1.8378\u001b[0m\n",
      "\u001b[34m{'loss': 1.8225, 'grad_norm': 1.06986403465271, 'learning_rate': 0.0009380530973451328, 'epoch': 0.09}\u001b[0m\n",
      "\u001b[34mStep 22: Loss = 1.8225\u001b[0m\n",
      "\u001b[34m{'loss': 1.7771, 'grad_norm': 0.9443598389625549, 'learning_rate': 0.0009336283185840708, 'epoch': 0.09}\u001b[0m\n",
      "\u001b[34mStep 23: Loss = 1.7771\u001b[0m\n",
      "\u001b[34m{'loss': 1.7802, 'grad_norm': 0.9292798042297363, 'learning_rate': 0.0009292035398230089, 'epoch': 0.1}\u001b[0m\n",
      "\u001b[34mStep 24: Loss = 1.7802\u001b[0m\n",
      "\u001b[34m{'loss': 1.7244, 'grad_norm': 0.9054421782493591, 'learning_rate': 0.0009247787610619469, 'epoch': 0.1}\u001b[0m\n",
      "\u001b[34mStep 25: Loss = 1.7244\u001b[0m\n",
      "\u001b[34m{'loss': 1.7913, 'grad_norm': 0.8925702571868896, 'learning_rate': 0.000920353982300885, 'epoch': 0.11}\u001b[0m\n",
      "\u001b[34mStep 26: Loss = 1.7913\u001b[0m\n",
      "\u001b[34m{'loss': 1.7914, 'grad_norm': 0.916957437992096, 'learning_rate': 0.000915929203539823, 'epoch': 0.11}\u001b[0m\n",
      "\u001b[34mStep 27: Loss = 1.7914\u001b[0m\n",
      "\u001b[34m{'loss': 1.7265, 'grad_norm': 0.8910645246505737, 'learning_rate': 0.000911504424778761, 'epoch': 0.12}\u001b[0m\n",
      "\u001b[34mStep 28: Loss = 1.7265\u001b[0m\n",
      "\u001b[34m{'loss': 1.7391, 'grad_norm': 0.8823187351226807, 'learning_rate': 0.0009070796460176991, 'epoch': 0.12}\u001b[0m\n",
      "\u001b[34mStep 29: Loss = 1.7391\u001b[0m\n",
      "\u001b[34m{'loss': 1.6869, 'grad_norm': 0.9225029349327087, 'learning_rate': 0.0009026548672566372, 'epoch': 0.12}\u001b[0m\n",
      "\u001b[34mStep 30: Loss = 1.6869\u001b[0m\n",
      "\u001b[34m{'loss': 1.6692, 'grad_norm': 0.8729566931724548, 'learning_rate': 0.0008982300884955752, 'epoch': 0.13}\u001b[0m\n",
      "\u001b[34mStep 31: Loss = 1.6692\u001b[0m\n",
      "\u001b[34m{'loss': 1.6762, 'grad_norm': 0.8898665308952332, 'learning_rate': 0.0008938053097345132, 'epoch': 0.13}\u001b[0m\n",
      "\u001b[34mStep 32: Loss = 1.6762\u001b[0m\n",
      "\u001b[34m{'loss': 1.6914, 'grad_norm': 0.9264739155769348, 'learning_rate': 0.0008893805309734513, 'epoch': 0.14}\u001b[0m\n",
      "\u001b[34mStep 33: Loss = 1.6914\u001b[0m\n",
      "\u001b[34m{'loss': 1.6956, 'grad_norm': 0.8698856830596924, 'learning_rate': 0.0008849557522123895, 'epoch': 0.14}\u001b[0m\n",
      "\u001b[34mStep 34: Loss = 1.6956\u001b[0m\n",
      "\u001b[34m{'loss': 1.6459, 'grad_norm': 0.9507430195808411, 'learning_rate': 0.0008805309734513275, 'epoch': 0.15}\u001b[0m\n",
      "\u001b[34mStep 35: Loss = 1.6459\u001b[0m\n",
      "\u001b[34m{'loss': 1.6078, 'grad_norm': 0.9161510467529297, 'learning_rate': 0.0008761061946902655, 'epoch': 0.15}\u001b[0m\n",
      "\u001b[34mStep 36: Loss = 1.6078\u001b[0m\n",
      "\u001b[34m{'loss': 1.5894, 'grad_norm': 0.8362436890602112, 'learning_rate': 0.0008716814159292035, 'epoch': 0.15}\u001b[0m\n",
      "\u001b[34mStep 37: Loss = 1.5894\u001b[0m\n",
      "\u001b[34m{'loss': 1.5655, 'grad_norm': 0.9414142966270447, 'learning_rate': 0.0008672566371681417, 'epoch': 0.16}\u001b[0m\n",
      "\u001b[34mStep 38: Loss = 1.5655\u001b[0m\n",
      "\u001b[34m{'loss': 1.5838, 'grad_norm': 0.947796642780304, 'learning_rate': 0.0008628318584070797, 'epoch': 0.16}\u001b[0m\n",
      "\u001b[34mStep 39: Loss = 1.5838\u001b[0m\n",
      "\u001b[34m{'loss': 1.595, 'grad_norm': 0.9322019815444946, 'learning_rate': 0.0008584070796460177, 'epoch': 0.17}\u001b[0m\n",
      "\u001b[34mStep 40: Loss = 1.5950\u001b[0m\n",
      "\u001b[34m{'loss': 1.5033, 'grad_norm': 0.9724403023719788, 'learning_rate': 0.0008539823008849557, 'epoch': 0.17}\u001b[0m\n",
      "\u001b[34mStep 41: Loss = 1.5033\u001b[0m\n",
      "\u001b[34m{'loss': 1.5391, 'grad_norm': 0.9693736433982849, 'learning_rate': 0.0008495575221238938, 'epoch': 0.18}\u001b[0m\n",
      "\u001b[34mStep 42: Loss = 1.5391\u001b[0m\n",
      "\u001b[34m{'loss': 1.5004, 'grad_norm': 1.0643633604049683, 'learning_rate': 0.0008451327433628319, 'epoch': 0.18}\u001b[0m\n",
      "\u001b[34mStep 43: Loss = 1.5004\u001b[0m\n",
      "\u001b[34m{'loss': 1.5613, 'grad_norm': 1.0188454389572144, 'learning_rate': 0.0008407079646017699, 'epoch': 0.18}\u001b[0m\n",
      "\u001b[34mStep 44: Loss = 1.5613\u001b[0m\n",
      "\u001b[34m{'loss': 1.4894, 'grad_norm': 1.0261648893356323, 'learning_rate': 0.0008362831858407079, 'epoch': 0.19}\u001b[0m\n",
      "\u001b[34mStep 45: Loss = 1.4894\u001b[0m\n",
      "\u001b[34m{'loss': 1.437, 'grad_norm': 1.0999504327774048, 'learning_rate': 0.000831858407079646, 'epoch': 0.19}\u001b[0m\n",
      "\u001b[34mStep 46: Loss = 1.4370\u001b[0m\n",
      "\u001b[34m{'loss': 1.4334, 'grad_norm': 1.0998942852020264, 'learning_rate': 0.000827433628318584, 'epoch': 0.2}\u001b[0m\n",
      "\u001b[34mStep 47: Loss = 1.4334\u001b[0m\n",
      "\u001b[34m{'loss': 1.4307, 'grad_norm': 1.1035492420196533, 'learning_rate': 0.0008230088495575221, 'epoch': 0.2}\u001b[0m\n",
      "\u001b[34mStep 48: Loss = 1.4307\u001b[0m\n",
      "\u001b[34m{'loss': 1.4604, 'grad_norm': 1.1862856149673462, 'learning_rate': 0.0008185840707964603, 'epoch': 0.21}\u001b[0m\n",
      "\u001b[34mStep 49: Loss = 1.4604\u001b[0m\n",
      "\u001b[34m{'loss': 1.4253, 'grad_norm': 1.1728531122207642, 'learning_rate': 0.0008141592920353983, 'epoch': 0.21}\u001b[0m\n",
      "\u001b[34mStep 50: Loss = 1.4253\u001b[0m\n",
      "\u001b[34m{'loss': 1.3599, 'grad_norm': 1.275278925895691, 'learning_rate': 0.0008097345132743363, 'epoch': 0.21}\u001b[0m\n",
      "\u001b[34mStep 51: Loss = 1.3599\u001b[0m\n",
      "\u001b[34m{'loss': 1.3951, 'grad_norm': 1.248653531074524, 'learning_rate': 0.0008053097345132744, 'epoch': 0.22}\u001b[0m\n",
      "\u001b[34mStep 52: Loss = 1.3951\u001b[0m\n",
      "\u001b[34m{'loss': 1.3581, 'grad_norm': 1.4117249250411987, 'learning_rate': 0.0008008849557522125, 'epoch': 0.22}\u001b[0m\n",
      "\u001b[34mStep 53: Loss = 1.3581\u001b[0m\n",
      "\u001b[34m{'loss': 1.3726, 'grad_norm': 1.2012912034988403, 'learning_rate': 0.0007964601769911505, 'epoch': 0.23}\u001b[0m\n",
      "\u001b[34mStep 54: Loss = 1.3726\u001b[0m\n",
      "\u001b[34m{'loss': 1.3313, 'grad_norm': 1.1654132604599, 'learning_rate': 0.0007920353982300885, 'epoch': 0.23}\u001b[0m\n",
      "\u001b[34mStep 55: Loss = 1.3313\u001b[0m\n",
      "\u001b[34m{'loss': 1.2847, 'grad_norm': 1.269989013671875, 'learning_rate': 0.0007876106194690265, 'epoch': 0.24}\u001b[0m\n",
      "\u001b[34mStep 56: Loss = 1.2847\u001b[0m\n",
      "\u001b[34m{'loss': 1.2958, 'grad_norm': 1.1164374351501465, 'learning_rate': 0.0007831858407079647, 'epoch': 0.24}\u001b[0m\n",
      "\u001b[34mStep 57: Loss = 1.2958\u001b[0m\n",
      "\u001b[34m{'loss': 1.3272, 'grad_norm': 1.2901959419250488, 'learning_rate': 0.0007787610619469027, 'epoch': 0.24}\u001b[0m\n",
      "\u001b[34mStep 58: Loss = 1.3272\u001b[0m\n",
      "\u001b[34m{'loss': 1.2861, 'grad_norm': 1.7707322835922241, 'learning_rate': 0.0007743362831858407, 'epoch': 0.25}\u001b[0m\n",
      "\u001b[34mStep 59: Loss = 1.2861\u001b[0m\n",
      "\u001b[34m{'loss': 1.2994, 'grad_norm': 2.134423017501831, 'learning_rate': 0.0007699115044247787, 'epoch': 0.25}\u001b[0m\n",
      "\u001b[34mStep 60: Loss = 1.2994\u001b[0m\n",
      "\u001b[34m{'loss': 1.2543, 'grad_norm': 1.986324667930603, 'learning_rate': 0.0007654867256637168, 'epoch': 0.26}\u001b[0m\n",
      "\u001b[34mStep 61: Loss = 1.2543\u001b[0m\n",
      "\u001b[34m{'loss': 1.2367, 'grad_norm': 1.1240893602371216, 'learning_rate': 0.0007610619469026549, 'epoch': 0.26}\u001b[0m\n",
      "\u001b[34mStep 62: Loss = 1.2367\u001b[0m\n",
      "\u001b[34m{'loss': 1.265, 'grad_norm': 1.11410653591156, 'learning_rate': 0.0007566371681415929, 'epoch': 0.27}\u001b[0m\n",
      "\u001b[34mStep 63: Loss = 1.2650\u001b[0m\n",
      "\u001b[34m{'loss': 1.2356, 'grad_norm': 0.911418080329895, 'learning_rate': 0.0007522123893805309, 'epoch': 0.27}\u001b[0m\n",
      "\u001b[34mStep 64: Loss = 1.2356\u001b[0m\n",
      "\u001b[34m{'loss': 1.2449, 'grad_norm': 0.8328925967216492, 'learning_rate': 0.0007477876106194691, 'epoch': 0.27}\u001b[0m\n",
      "\u001b[34mStep 65: Loss = 1.2449\u001b[0m\n",
      "\u001b[34m{'loss': 1.3013, 'grad_norm': 0.914576530456543, 'learning_rate': 0.0007433628318584072, 'epoch': 0.28}\u001b[0m\n",
      "\u001b[34mStep 66: Loss = 1.3013\u001b[0m\n",
      "\u001b[34m{'loss': 1.2739, 'grad_norm': 0.8859279155731201, 'learning_rate': 0.0007389380530973452, 'epoch': 0.28}\u001b[0m\n",
      "\u001b[34mStep 67: Loss = 1.2739\u001b[0m\n",
      "\u001b[34m{'loss': 1.2374, 'grad_norm': 1.0523165464401245, 'learning_rate': 0.0007345132743362832, 'epoch': 0.29}\u001b[0m\n",
      "\u001b[34mStep 68: Loss = 1.2374\u001b[0m\n",
      "\u001b[34m{'loss': 1.234, 'grad_norm': 0.8947208523750305, 'learning_rate': 0.0007300884955752213, 'epoch': 0.29}\u001b[0m\n",
      "\u001b[34mStep 69: Loss = 1.2340\u001b[0m\n",
      "\u001b[34m{'loss': 1.2035, 'grad_norm': 0.9666450023651123, 'learning_rate': 0.0007256637168141593, 'epoch': 0.3}\u001b[0m\n",
      "\u001b[34mStep 70: Loss = 1.2035\u001b[0m\n",
      "\u001b[34m{'loss': 1.1865, 'grad_norm': 0.9628391861915588, 'learning_rate': 0.0007212389380530974, 'epoch': 0.3}\u001b[0m\n",
      "\u001b[34mStep 71: Loss = 1.1865\u001b[0m\n",
      "\u001b[34m{'loss': 1.2198, 'grad_norm': 0.8731601238250732, 'learning_rate': 0.0007168141592920354, 'epoch': 0.3}\u001b[0m\n",
      "\u001b[34mStep 72: Loss = 1.2198\u001b[0m\n",
      "\u001b[34m{'loss': 1.2572, 'grad_norm': 0.8449949622154236, 'learning_rate': 0.0007123893805309735, 'epoch': 0.31}\u001b[0m\n",
      "\u001b[34mStep 73: Loss = 1.2572\u001b[0m\n",
      "\u001b[34m{'loss': 1.1681, 'grad_norm': 0.8850548267364502, 'learning_rate': 0.0007079646017699115, 'epoch': 0.31}\u001b[0m\n",
      "\u001b[34mStep 74: Loss = 1.1681\u001b[0m\n",
      "\u001b[34m{'loss': 1.1223, 'grad_norm': 0.8564367294311523, 'learning_rate': 0.0007035398230088495, 'epoch': 0.32}\u001b[0m\n",
      "\u001b[34mStep 75: Loss = 1.1223\u001b[0m\n",
      "\u001b[34m{'loss': 1.1769, 'grad_norm': 0.8485937714576721, 'learning_rate': 0.0006991150442477876, 'epoch': 0.32}\u001b[0m\n",
      "\u001b[34mStep 76: Loss = 1.1769\u001b[0m\n",
      "\u001b[34m{'loss': 1.1674, 'grad_norm': 0.8565574288368225, 'learning_rate': 0.0006946902654867257, 'epoch': 0.33}\u001b[0m\n",
      "\u001b[34mStep 77: Loss = 1.1674\u001b[0m\n",
      "\u001b[34m{'loss': 1.1905, 'grad_norm': 0.8706735968589783, 'learning_rate': 0.0006902654867256637, 'epoch': 0.33}\u001b[0m\n",
      "\u001b[34mStep 78: Loss = 1.1905\u001b[0m\n",
      "\u001b[34m{'loss': 1.1597, 'grad_norm': 0.8835492134094238, 'learning_rate': 0.0006858407079646017, 'epoch': 0.33}\u001b[0m\n",
      "\u001b[34mStep 79: Loss = 1.1597\u001b[0m\n",
      "\u001b[34m{'loss': 1.169, 'grad_norm': 0.9517481327056885, 'learning_rate': 0.0006814159292035397, 'epoch': 0.34}\u001b[0m\n",
      "\u001b[34mStep 80: Loss = 1.1690\u001b[0m\n",
      "\u001b[34m{'loss': 1.1518, 'grad_norm': 0.9995867013931274, 'learning_rate': 0.000676991150442478, 'epoch': 0.34}\u001b[0m\n",
      "\u001b[34mStep 81: Loss = 1.1518\u001b[0m\n",
      "\u001b[34m{'loss': 1.1639, 'grad_norm': 0.8538850545883179, 'learning_rate': 0.000672566371681416, 'epoch': 0.35}\u001b[0m\n",
      "\u001b[34mStep 82: Loss = 1.1639\u001b[0m\n",
      "\u001b[34m{'loss': 1.1707, 'grad_norm': 1.0619152784347534, 'learning_rate': 0.000668141592920354, 'epoch': 0.35}\u001b[0m\n",
      "\u001b[34mStep 83: Loss = 1.1707\u001b[0m\n",
      "\u001b[34m{'loss': 1.0879, 'grad_norm': 0.9287571907043457, 'learning_rate': 0.0006637168141592921, 'epoch': 0.36}\u001b[0m\n",
      "\u001b[34mStep 84: Loss = 1.0879\u001b[0m\n",
      "\u001b[34m{'loss': 1.1102, 'grad_norm': 0.9442043900489807, 'learning_rate': 0.0006592920353982302, 'epoch': 0.36}\u001b[0m\n",
      "\u001b[34mStep 85: Loss = 1.1102\u001b[0m\n",
      "\u001b[34m{'loss': 1.1216, 'grad_norm': 1.0370407104492188, 'learning_rate': 0.0006548672566371682, 'epoch': 0.36}\u001b[0m\n",
      "\u001b[34mStep 86: Loss = 1.1216\u001b[0m\n",
      "\u001b[34m{'loss': 1.0687, 'grad_norm': 0.961850643157959, 'learning_rate': 0.0006504424778761062, 'epoch': 0.37}\u001b[0m\n",
      "\u001b[34mStep 87: Loss = 1.0687\u001b[0m\n",
      "\u001b[34m{'loss': 1.1073, 'grad_norm': 0.9987707734107971, 'learning_rate': 0.0006460176991150443, 'epoch': 0.37}\u001b[0m\n",
      "\u001b[34mStep 88: Loss = 1.1073\u001b[0m\n",
      "\u001b[34m{'loss': 1.1458, 'grad_norm': 0.9583374261856079, 'learning_rate': 0.0006415929203539823, 'epoch': 0.38}\u001b[0m\n",
      "\u001b[34mStep 89: Loss = 1.1458\u001b[0m\n",
      "\u001b[34m{'loss': 1.0892, 'grad_norm': 0.9562974572181702, 'learning_rate': 0.0006371681415929204, 'epoch': 0.38}\u001b[0m\n",
      "\u001b[34mStep 90: Loss = 1.0892\u001b[0m\n",
      "\u001b[34m{'loss': 1.0726, 'grad_norm': 0.9667190909385681, 'learning_rate': 0.0006327433628318584, 'epoch': 0.39}\u001b[0m\n",
      "\u001b[34mStep 91: Loss = 1.0726\u001b[0m\n",
      "\u001b[34m{'loss': 1.0748, 'grad_norm': 1.0628995895385742, 'learning_rate': 0.0006283185840707965, 'epoch': 0.39}\u001b[0m\n",
      "\u001b[34mStep 92: Loss = 1.0748\u001b[0m\n",
      "\u001b[34m{'loss': 1.0506, 'grad_norm': 1.0377590656280518, 'learning_rate': 0.0006238938053097345, 'epoch': 0.39}\u001b[0m\n",
      "\u001b[34mStep 93: Loss = 1.0506\u001b[0m\n",
      "\u001b[34m{'loss': 1.0418, 'grad_norm': 1.053757905960083, 'learning_rate': 0.0006194690265486725, 'epoch': 0.4}\u001b[0m\n",
      "\u001b[34mStep 94: Loss = 1.0418\u001b[0m\n",
      "\u001b[34m{'loss': 1.0536, 'grad_norm': 1.0221678018569946, 'learning_rate': 0.0006150442477876106, 'epoch': 0.4}\u001b[0m\n",
      "\u001b[34mStep 95: Loss = 1.0536\u001b[0m\n",
      "\u001b[34m{'loss': 1.0957, 'grad_norm': 1.1512125730514526, 'learning_rate': 0.0006106194690265487, 'epoch': 0.41}\u001b[0m\n",
      "\u001b[34mStep 96: Loss = 1.0957\u001b[0m\n",
      "\u001b[34m{'loss': 1.0913, 'grad_norm': 1.0041476488113403, 'learning_rate': 0.0006061946902654868, 'epoch': 0.41}\u001b[0m\n",
      "\u001b[34mStep 97: Loss = 1.0913\u001b[0m\n",
      "\u001b[34m{'loss': 1.0166, 'grad_norm': 1.078669548034668, 'learning_rate': 0.0006017699115044248, 'epoch': 0.42}\u001b[0m\n",
      "\u001b[34mStep 98: Loss = 1.0166\u001b[0m\n",
      "\u001b[34m{'loss': 1.0122, 'grad_norm': 1.0471851825714111, 'learning_rate': 0.0005973451327433628, 'epoch': 0.42}\u001b[0m\n",
      "\u001b[34mStep 99: Loss = 1.0122\u001b[0m\n",
      "\u001b[34m{'loss': 1.0362, 'grad_norm': 0.9615678787231445, 'learning_rate': 0.000592920353982301, 'epoch': 0.42}\u001b[0m\n",
      "\u001b[34mStep 100: Loss = 1.0362\u001b[0m\n",
      "\u001b[34m{'loss': 1.0236, 'grad_norm': 1.0628297328948975, 'learning_rate': 0.000588495575221239, 'epoch': 0.43}\u001b[0m\n",
      "\u001b[34mStep 101: Loss = 1.0236\u001b[0m\n",
      "\u001b[34m{'loss': 1.0396, 'grad_norm': 1.0147632360458374, 'learning_rate': 0.000584070796460177, 'epoch': 0.43}\u001b[0m\n",
      "\u001b[34mStep 102: Loss = 1.0396\u001b[0m\n",
      "\u001b[34m{'loss': 1.0414, 'grad_norm': 1.1183717250823975, 'learning_rate': 0.000579646017699115, 'epoch': 0.44}\u001b[0m\n",
      "\u001b[34mStep 103: Loss = 1.0414\u001b[0m\n",
      "\u001b[34m{'loss': 1.0464, 'grad_norm': 1.098677635192871, 'learning_rate': 0.0005752212389380532, 'epoch': 0.44}\u001b[0m\n",
      "\u001b[34mStep 104: Loss = 1.0464\u001b[0m\n",
      "\u001b[34m{'loss': 0.965, 'grad_norm': 1.0824111700057983, 'learning_rate': 0.0005707964601769912, 'epoch': 0.45}\u001b[0m\n",
      "\u001b[34m#015  0%|          | 1/233 [00:07<28:35,  7.39s/it]#015                                               #015#015  0%|          | 1/233 [00:07<28:35,  7.39s/it]#015  1%|          | 2/233 [00:13<26:23,  6.86s/it]#015                                               #015#015  1%|          | 2/233 [00:13<26:23,  6.86s/it]#015  1%|‚ñè         | 3/233 [00:20<25:20,  6.61s/it]#015                                               #015#015  1%|‚ñè         | 3/233 [00:20<25:20,  6.61s/it]#015  2%|‚ñè         | 4/233 [00:26<24:49,  6.50s/it]#015                                               #015#015  2%|‚ñè         | 4/233 [00:26<24:49,  6.50s/it]#015  2%|‚ñè         | 5/233 [00:32<24:30,  6.45s/it]#015                                               #015#015  2%|‚ñè         | 5/233 [00:32<24:30,  6.45s/it]#015  3%|‚ñé         | 6/233 [00:39<24:10,  6.39s/it]#015                                               #015#015  3%|‚ñé         | 6/233 [00:39<24:10,  6.39s/it]#015  3%|‚ñé         | 7/233 [00:45<24:00,  6.38s/it]#015                                               #015#015  3%|‚ñé         | 7/233 [00:45<24:00,  6.38s/it]#015  3%|‚ñé         | 8/233 [00:52<24:03,  6.41s/it]#015                                               #015#015  3%|‚ñé         | 8/233 [00:52<24:03,  6.41s/it]#015  4%|‚ñç         | 9/233 [00:58<23:53,  6.40s/it]#015                                               #015#015  4%|‚ñç         | 9/233 [00:58<23:53,  6.40s/it]#015  4%|‚ñç         | 10/233 [01:04<23:43,  6.38s/it]#015                                                #015#015  4%|‚ñç         | 10/233 [01:04<23:43,  6.38s/it]#015  5%|‚ñç         | 11/233 [01:11<23:34,  6.37s/it]#015                                                #015#015  5%|‚ñç         | 11/233 [01:11<23:34,  6.37s/it]#015  5%|‚ñå         | 12/233 [01:17<23:24,  6.35s/it]#015                                                #015#015  5%|‚ñå         | 12/233 [01:17<23:24,  6.35s/it]#015  6%|‚ñå         | 13/233 [01:23<23:15,  6.34s/it]#015                                                #015#015  6%|‚ñå         | 13/233 [01:23<23:15,  6.34s/it]#015  6%|‚ñå         | 14/233 [01:30<23:11,  6.35s/it]#015                                                #015#015  6%|‚ñå         | 14/233 [01:30<23:11,  6.35s/it]#015  6%|‚ñã         | 15/233 [01:36<23:12,  6.39s/it]#015                                                #015#015  6%|‚ñã         | 15/233 [01:36<23:12,  6.39s/it]#015  7%|‚ñã         | 16/233 [01:42<23:04,  6.38s/it]#015                                                #015#015  7%|‚ñã         | 16/233 [01:42<23:04,  6.38s/it]#015  7%|‚ñã         | 17/233 [01:49<22:55,  6.37s/it]#015                                                #015#015  7%|‚ñã         | 17/233 [01:49<22:55,  6.37s/it]#015  8%|‚ñä         | 18/233 [01:55<22:48,  6.36s/it]#015                                                #015#015  8%|‚ñä         | 18/233 [01:55<22:48,  6.36s/it]#015  8%|‚ñä         | 19/233 [02:01<22:36,  6.34s/it]#015                                                #015#015  8%|‚ñä         | 19/233 [02:01<22:36,  6.34s/it]#015  9%|‚ñä         | 20/233 [02:08<22:27,  6.33s/it]#015                                                #015#015  9%|‚ñä         | 20/233 [02:08<22:27,  6.33s/it]#015  9%|‚ñâ         | 21/233 [02:14<22:20,  6.32s/it]#015                                                #015#015  9%|‚ñâ         | 21/233 [02:14<22:20,  6.32s/it]#015  9%|‚ñâ         | 22/233 [02:20<22:14,  6.33s/it]#015                                                #015#015  9%|‚ñâ         | 22/233 [02:20<22:14,  6.33s/it]#015 10%|‚ñâ         | 23/233 [02:27<22:18,  6.37s/it]#015                                                #015#015 10%|‚ñâ         | 23/233 [02:27<22:18,  6.37s/it]#015 10%|‚ñà         | 24/233 [02:33<22:13,  6.38s/it]#015                                                #015#015 10%|‚ñà         | 24/233 [02:33<22:13,  6.38s/it]#015 11%|‚ñà         | 25/233 [02:40<22:02,  6.36s/it]#015                                                #015#015 11%|‚ñà         | 25/233 [02:40<22:02,  6.36s/it]#015 11%|‚ñà         | 26/233 [02:46<21:55,  6.36s/it]#015                                                #015#015 11%|‚ñà         | 26/233 [02:46<21:55,  6.36s/it]#015 12%|‚ñà‚ñè        | 27/233 [02:52<21:49,  6.36s/it]#015                                                #015#015 12%|‚ñà‚ñè        | 27/233 [02:52<21:49,  6.36s/it]#015 12%|‚ñà‚ñè        | 28/233 [02:59<21:42,  6.35s/it]#015                                                #015#015 12%|‚ñà‚ñè        | 28/233 [02:59<21:42,  6.35s/it]#015 12%|‚ñà‚ñè        | 29/233 [03:05<21:35,  6.35s/it]#015                                                #015#015 12%|‚ñà‚ñè        | 29/233 [03:05<21:35,  6.35s/it]#015 13%|‚ñà‚ñé        | 30/233 [03:11<21:27,  6.34s/it]#015                                                #015#015 13%|‚ñà‚ñé        | 30/233 [03:11<21:27,  6.34s/it]#015 13%|‚ñà‚ñé        | 31/233 [03:18<21:31,  6.39s/it]#015                                                #015#015 13%|‚ñà‚ñé        | 31/233 [03:18<21:31,  6.39s/it]#015 14%|‚ñà‚ñé        | 32/233 [03:24<21:21,  6.38s/it]#015                                                #015#015 14%|‚ñà‚ñé        | 32/233 [03:24<21:21,  6.38s/it]#015 14%|‚ñà‚ñç        | 33/233 [03:30<21:15,  6.38s/it]#015                                                #015#015 14%|‚ñà‚ñç        | 33/233 [03:30<21:15,  6.38s/it]#015 15%|‚ñà‚ñç        | 34/233 [03:37<21:05,  6.36s/it]#015                                                #015#015 15%|‚ñà‚ñç        | 34/233 [03:37<21:05,  6.36s/it]#015 15%|‚ñà‚ñå        | 35/233 [03:43<20:55,  6.34s/it]#015                                                #015#015 15%|‚ñà‚ñå        | 35/233 [03:43<20:55,  6.34s/it]#015 15%|‚ñà‚ñå        | 36/233 [03:49<20:44,  6.31s/it]#015                                                #015#015 15%|‚ñà‚ñå        | 36/233 [03:49<20:44,  6.31s/it]#015 16%|‚ñà‚ñå        | 37/233 [03:56<20:40,  6.33s/it]#015                                                #015#015 16%|‚ñà‚ñå        | 37/233 [03:56<20:40,  6.33s/it]#015 16%|‚ñà‚ñã        | 38/233 [04:02<20:42,  6.37s/it]#015                                                #015#015 16%|‚ñà‚ñã        | 38/233 [04:02<20:42,  6.37s/it]#015 17%|‚ñà‚ñã        | 39/233 [04:09<20:34,  6.37s/it]#015                                                #015#015 17%|‚ñà‚ñã        | 39/233 [04:09<20:34,  6.37s/it]#015 17%|‚ñà‚ñã        | 40/233 [04:15<20:26,  6.35s/it]#015                                                #015#015 17%|‚ñà‚ñã        | 40/233 [04:15<20:26,  6.35s/it]#015 18%|‚ñà‚ñä        | 41/233 [04:21<20:19,  6.35s/it]#015                                                #015#015 18%|‚ñà‚ñä        | 41/233 [04:21<20:19,  6.35s/it]#015 18%|‚ñà‚ñä        | 42/233 [04:28<20:15,  6.36s/it]#015                                                #015#015 18%|‚ñà‚ñä        | 42/233 [04:28<20:15,  6.36s/it]#015 18%|‚ñà‚ñä        | 43/233 [04:34<20:04,  6.34s/it]#015                                                #015#015 18%|‚ñà‚ñä        | 43/233 [04:34<20:04,  6.34s/it]#015 19%|‚ñà‚ñâ        | 44/233 [04:40<19:57,  6.34s/it]#015                                                #015#015 19%|‚ñà‚ñâ        | 44/233 [04:40<19:57,  6.34s/it]#015 19%|‚ñà‚ñâ        | 45/233 [04:47<19:51,  6.34s/it]#015                                                #015#015 19%|‚ñà‚ñâ        | 45/233 [04:47<19:51,  6.34s/it]#015 20%|‚ñà‚ñâ        | 46/233 [04:53<19:52,  6.38s/it]#015                                                #015#015 20%|‚ñà‚ñâ        | 46/233 [04:53<19:52,  6.38s/it]#015 20%|‚ñà‚ñà        | 47/233 [04:59<19:41,  6.35s/it]#015                                                #015#015 20%|‚ñà‚ñà        | 47/233 [04:59<19:41,  6.35s/it]#015 21%|‚ñà‚ñà        | 48/233 [05:06<19:32,  6.34s/it]#015                                                #015#015 21%|‚ñà‚ñà        | 48/233 [05:06<19:32,  6.34s/it]#015 21%|‚ñà‚ñà        | 49/233 [05:12<19:23,  6.33s/it]#015                                                #015#015 21%|‚ñà‚ñà        | 49/233 [05:12<19:23,  6.33s/it]#015 21%|‚ñà‚ñà‚ñè       | 50/233 [05:18<19:18,  6.33s/it]#015                                                #015#015 21%|‚ñà‚ñà‚ñè       | 50/233 [05:18<19:18,  6.33s/it]#015 22%|‚ñà‚ñà‚ñè       | 51/233 [05:25<19:10,  6.32s/it]#015                                                #015#015 22%|‚ñà‚ñà‚ñè       | 51/233 [05:25<19:10,  6.32s/it]#015 22%|‚ñà‚ñà‚ñè       | 52/233 [05:31<19:05,  6.33s/it]#015                                                #015#015 22%|‚ñà‚ñà‚ñè       | 52/233 [05:31<19:05,  6.33s/it]#015 23%|‚ñà‚ñà‚ñé       | 53/233 [05:37<18:58,  6.32s/it]#015                                                #015#015 23%|‚ñà‚ñà‚ñé       | 53/233 [05:37<18:58,  6.32s/it]#015 23%|‚ñà‚ñà‚ñé       | 54/233 [05:44<18:58,  6.36s/it]#015                                                #015#015 23%|‚ñà‚ñà‚ñé       | 54/233 [05:44<18:58,  6.36s/it]#015 24%|‚ñà‚ñà‚ñé       | 55/233 [05:50<18:51,  6.36s/it]#015                                                #015#015 24%|‚ñà‚ñà‚ñé       | 55/233 [05:50<18:51,  6.36s/it]#015 24%|‚ñà‚ñà‚ñç       | 56/233 [05:56<18:44,  6.35s/it]#015                                                #015#015 24%|‚ñà‚ñà‚ñç       | 56/233 [05:56<18:44,  6.35s/it]#015 24%|‚ñà‚ñà‚ñç       | 57/233 [06:03<18:34,  6.33s/it]#015                                                #015#015 24%|‚ñà‚ñà‚ñç       | 57/233 [06:03<18:34,  6.33s/it]#015 25%|‚ñà‚ñà‚ñç       | 58/233 [06:09<18:26,  6.32s/it]#015                                                #015#015 25%|‚ñà‚ñà‚ñç       | 58/233 [06:09<18:26,  6.32s/it]#015 25%|‚ñà‚ñà‚ñå       | 59/233 [06:15<18:19,  6.32s/it]#015                                                #015#015 25%|‚ñà‚ñà‚ñå       | 59/233 [06:15<18:19,  6.32s/it]#015 26%|‚ñà‚ñà‚ñå       | 60/233 [06:22<18:14,  6.33s/it]#015                                                #015#015 26%|‚ñà‚ñà‚ñå       | 60/233 [06:22<18:14,  6.33s/it]#015 26%|‚ñà‚ñà‚ñå       | 61/233 [06:28<18:17,  6.38s/it]#015                                                #015#015 26%|‚ñà‚ñà‚ñå       | 61/233 [06:28<18:17,  6.38s/it]#015 27%|‚ñà‚ñà‚ñã       | 62/233 [06:34<18:09,  6.37s/it]#015                                                #015#015 27%|‚ñà‚ñà‚ñã       | 62/233 [06:34<18:09,  6.37s/it]#015 27%|‚ñà‚ñà‚ñã       | 63/233 [06:41<18:02,  6.37s/it]#015                                                #015#015 27%|‚ñà‚ñà‚ñã       | 63/233 [06:41<18:02,  6.37s/it]#015 27%|‚ñà‚ñà‚ñã       | 64/233 [06:47<17:55,  6.37s/it]#015                                                #015#015 27%|‚ñà‚ñà‚ñã       | 64/233 [06:47<17:55,  6.37s/it]#015 28%|‚ñà‚ñà‚ñä       | 65/233 [06:53<17:46,  6.35s/it]#015                                                #015#015 28%|‚ñà‚ñà‚ñä       | 65/233 [06:53<17:46,  6.35s/it]#015 28%|‚ñà‚ñà‚ñä       | 66/233 [07:00<17:40,  6.35s/it]#015                                                #015#015 28%|‚ñà‚ñà‚ñä       | 66/233 [07:00<17:40,  6.35s/it]#015 29%|‚ñà‚ñà‚ñâ       | 67/233 [07:06<17:31,  6.34s/it]#015                                                #015#015 29%|‚ñà‚ñà‚ñâ       | 67/233 [07:06<17:31,  6.34s/it]#015 29%|‚ñà‚ñà‚ñâ       | 68/233 [07:12<17:24,  6.33s/it]#015                                                #015#015 29%|‚ñà‚ñà‚ñâ       | 68/233 [07:12<17:24,  6.33s/it]#015 30%|‚ñà‚ñà‚ñâ       | 69/233 [07:19<17:25,  6.37s/it]#015                                                #015#015 30%|‚ñà‚ñà‚ñâ       | 69/233 [07:19<17:25,  6.37s/it]#015 30%|‚ñà‚ñà‚ñà       | 70/233 [07:25<17:16,  6.36s/it]#015                                                #015#015 30%|‚ñà‚ñà‚ñà       | 70/233 [07:25<17:16,  6.36s/it]#015 30%|‚ñà‚ñà‚ñà       | 71/233 [07:32<17:10,  6.36s/it]#015                                                #015#015 30%|‚ñà‚ñà‚ñà       | 71/233 [07:32<17:10,  6.36s/it]#015 31%|‚ñà‚ñà‚ñà       | 72/233 [07:38<17:04,  6.36s/it]#015                                                #015#015 31%|‚ñà‚ñà‚ñà       | 72/233 [07:38<17:04,  6.36s/it]#015 31%|‚ñà‚ñà‚ñà‚ñè      | 73/233 [07:44<16:55,  6.35s/it]#015                                                #015#015 31%|‚ñà‚ñà‚ñà‚ñè      | 73/233 [07:44<16:55,  6.35s/it]#015 32%|‚ñà‚ñà‚ñà‚ñè      | 74/233 [07:51<16:49,  6.35s/it]#015                                                #015#015 32%|‚ñà‚ñà‚ñà‚ñè      | 74/233 [07:51<16:49,  6.35s/it]#015 32%|‚ñà‚ñà‚ñà‚ñè      | 75/233 [07:57<16:42,  6.34s/it]#015                                                #015#015 32%|‚ñà‚ñà‚ñà‚ñè      | 75/233 [07:57<16:42,  6.34s/it]#015 33%|‚ñà‚ñà‚ñà‚ñé      | 76/233 [08:03<16:35,  6.34s/it]#015                                                #015#015 33%|‚ñà‚ñà‚ñà‚ñé      | 76/233 [08:03<16:35,  6.34s/it]#015 33%|‚ñà‚ñà‚ñà‚ñé      | 77/233 [08:10<16:35,  6.38s/it]#015                                                #015#015 33%|‚ñà‚ñà‚ñà‚ñé      | 77/233 [08:10<16:35,  6.38s/it]#015 33%|‚ñà‚ñà‚ñà‚ñé      | 78/233 [08:16<16:26,  6.36s/it]#015                                                #015#015 33%|‚ñà‚ñà‚ñà‚ñé      | 78/233 [08:16<16:26,  6.36s/it]#015 34%|‚ñà‚ñà‚ñà‚ñç      | 79/233 [08:22<16:18,  6.35s/it]#015                                                #015#015 34%|‚ñà‚ñà‚ñà‚ñç      | 79/233 [08:22<16:18,  6.35s/it]#015 34%|‚ñà‚ñà‚ñà‚ñç      | 80/233 [08:29<16:13,  6.36s/it]#015                                                #015#015 34%|‚ñà‚ñà‚ñà‚ñç      | 80/233 [08:29<16:13,  6.36s/it]#015 35%|‚ñà‚ñà‚ñà‚ñç      | 81/233 [08:35<16:06,  6.36s/it]#015                                                #015#015 35%|‚ñà‚ñà‚ñà‚ñç      | 81/233 [08:35<16:06,  6.36s/it]#015 35%|‚ñà‚ñà‚ñà‚ñå      | 82/233 [08:41<15:59,  6.35s/it]#015                                                #015#015 35%|‚ñà‚ñà‚ñà‚ñå      | 82/233 [08:41<15:59,  6.35s/it]#015 36%|‚ñà‚ñà‚ñà‚ñå      | 83/233 [08:48<15:51,  6.34s/it]#015                                                #015#015 36%|‚ñà‚ñà‚ñà‚ñå      | 83/233 [08:48<15:51,  6.34s/it]#015 36%|‚ñà‚ñà‚ñà‚ñå      | 84/233 [08:54<15:50,  6.38s/it]#015                                                #015#015 36%|‚ñà‚ñà‚ñà‚ñå      | 84/233 [08:54<15:50,  6.38s/it]#015 36%|‚ñà‚ñà‚ñà‚ñã      | 85/233 [09:01<15:41,  6.36s/it]#015                                                #015#015 36%|‚ñà‚ñà‚ñà‚ñã      | 85/233 [09:01<15:41,  6.36s/it]#015 37%|‚ñà‚ñà‚ñà‚ñã      | 86/233 [09:07<15:33,  6.35s/it]#015                                                #015#015 37%|‚ñà‚ñà‚ñà‚ñã      | 86/233 [09:07<15:33,  6.35s/it]#015 37%|‚ñà‚ñà‚ñà‚ñã      | 87/233 [09:13<15:26,  6.35s/it]#015                                                #015#015 37%|‚ñà‚ñà‚ñà‚ñã      | 87/233 [09:13<15:26,  6.35s/it]#015 38%|‚ñà‚ñà‚ñà‚ñä      | 88/233 [09:20<15:18,  6.33s/it]#015                                                #015#015 38%|‚ñà‚ñà‚ñà‚ñä      | 88/233 [09:20<15:18,  6.33s/it]#015 38%|‚ñà‚ñà‚ñà‚ñä      | 89/233 [09:26<15:12,  6.34s/it]#015                                                #015#015 38%|‚ñà‚ñà‚ñà‚ñä      | 89/233 [09:26<15:12,  6.34s/it]#015 39%|‚ñà‚ñà‚ñà‚ñä      | 90/233 [09:32<15:06,  6.34s/it]#015                                                #015#015 39%|‚ñà‚ñà‚ñà‚ñä      | 90/233 [09:32<15:06,  6.34s/it]#015 39%|‚ñà‚ñà‚ñà‚ñâ      | 91/233 [09:39<14:58,  6.33s/it]#015                                                #015#015 39%|‚ñà‚ñà‚ñà‚ñâ      | 91/233 [09:39<14:58,  6.33s/it]#015 39%|‚ñà‚ñà‚ñà‚ñâ      | 92/233 [09:45<14:57,  6.36s/it]#015                                                #015#015 39%|‚ñà‚ñà‚ñà‚ñâ      | 92/233 [09:45<14:57,  6.36s/it]#015 40%|‚ñà‚ñà‚ñà‚ñâ      | 93/233 [09:51<14:48,  6.35s/it]#015                                                #015#015 40%|‚ñà‚ñà‚ñà‚ñâ      | 93/233 [09:51<14:48,  6.35s/it]#015 40%|‚ñà‚ñà‚ñà‚ñà      | 94/233 [09:58<14:41,  6.34s/it]#015                                                #015#015 40%|‚ñà‚ñà‚ñà‚ñà      | 94/233 [09:58<14:41,  6.34s/it]#015 41%|‚ñà‚ñà‚ñà‚ñà      | 95/233 [10:04<14:35,  6.34s/it]#015                                                #015#015 41%|‚ñà‚ñà‚ñà‚ñà      | 95/233 [10:04<14:35,  6.34s/it]#015 41%|‚ñà‚ñà‚ñà‚ñà      | 96/233 [10:10<14:29,  6.34s/it]#015                                                #015#015 41%|‚ñà‚ñà‚ñà‚ñà      | 96/233 [10:10<14:29,  6.34s/it]#015 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 97/233 [10:17<14:22,  6.34s/it]#015                                                #015#015 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 97/233 [10:17<14:22,  6.34s/it]#015 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 98/233 [10:23<14:14,  6.33s/it]#015                                                #015#015 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 98/233 [10:23<14:14,  6.33s/it]#015 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 99/233 [10:29<14:09,  6.34s/it]#015                                                #015#015 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 99/233 [10:29<14:09,  6.34s/it]#015 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 100/233 [10:36<14:08,  6.38s/it]#015                                                 #015#015 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 100/233 [10:36<14:08,  6.38s/it]#015 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 101/233 [10:42<13:59,  6.36s/it]#015                                                 #015#015 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 101/233 [10:42<13:59,  6.36s/it]#015 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 102/233 [10:48<13:51,  6.35s/it]#015                                                 #015#015 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 102/233 [10:48<13:51,  6.35s/it]#015 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 103/233 [10:55<13:44,  6.34s/it]#015                                                 #015#015 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 103/233 [10:55<13:44,  6.34s/it]#015 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 104/233 [11:01<13:38,  6.34s/it]#015              \u001b[0m\n",
      "\u001b[34mStep 105: Loss = 0.9650\u001b[0m\n",
      "\u001b[34m{'loss': 0.9258, 'grad_norm': 1.1044200658798218, 'learning_rate': 0.0005663716814159292, 'epoch': 0.45}\u001b[0m\n",
      "\u001b[34mStep 106: Loss = 0.9258\u001b[0m\n",
      "\u001b[34m{'loss': 0.9928, 'grad_norm': 1.0502740144729614, 'learning_rate': 0.0005619469026548672, 'epoch': 0.45}\u001b[0m\n",
      "\u001b[34mStep 107: Loss = 0.9928\u001b[0m\n",
      "\u001b[34m{'loss': 0.9741, 'grad_norm': 1.001561164855957, 'learning_rate': 0.0005575221238938053, 'epoch': 0.46}\u001b[0m\n",
      "\u001b[34mStep 108: Loss = 0.9741\u001b[0m\n",
      "\u001b[34m{'loss': 0.9901, 'grad_norm': 1.086859941482544, 'learning_rate': 0.0005530973451327434, 'epoch': 0.46}\u001b[0m\n",
      "\u001b[34mStep 109: Loss = 0.9901\u001b[0m\n",
      "\u001b[34m{'loss': 1.0129, 'grad_norm': 0.99544757604599, 'learning_rate': 0.0005486725663716814, 'epoch': 0.47}\u001b[0m\n",
      "\u001b[34mStep 110: Loss = 1.0129\u001b[0m\n",
      "\u001b[34m{'loss': 1.0026, 'grad_norm': 1.0647997856140137, 'learning_rate': 0.0005442477876106194, 'epoch': 0.47}\u001b[0m\n",
      "\u001b[34mStep 111: Loss = 1.0026\u001b[0m\n",
      "\u001b[34m{'loss': 0.9056, 'grad_norm': 1.0614674091339111, 'learning_rate': 0.0005398230088495575, 'epoch': 0.48}\u001b[0m\n",
      "\u001b[34mStep 112: Loss = 0.9056\u001b[0m\n",
      "\u001b[34m{'loss': 0.984, 'grad_norm': 0.9176657795906067, 'learning_rate': 0.0005353982300884956, 'epoch': 0.48}\u001b[0m\n",
      "\u001b[34mStep 113: Loss = 0.9840\u001b[0m\n",
      "\u001b[34m{'loss': 0.983, 'grad_norm': 0.9115254878997803, 'learning_rate': 0.0005309734513274337, 'epoch': 0.48}\u001b[0m\n",
      "\u001b[34mStep 114: Loss = 0.9830\u001b[0m\n",
      "\u001b[34m{'loss': 0.9515, 'grad_norm': 0.9010834097862244, 'learning_rate': 0.0005265486725663717, 'epoch': 0.49}\u001b[0m\n",
      "\u001b[34mStep 115: Loss = 0.9515\u001b[0m\n",
      "\u001b[34m{'loss': 0.9149, 'grad_norm': 0.9831101894378662, 'learning_rate': 0.0005221238938053098, 'epoch': 0.49}\u001b[0m\n",
      "\u001b[34mStep 116: Loss = 0.9149\u001b[0m\n",
      "\u001b[34m{'loss': 0.8632, 'grad_norm': 1.0248115062713623, 'learning_rate': 0.0005176991150442478, 'epoch': 0.5}\u001b[0m\n",
      "\u001b[34mStep 117: Loss = 0.8632\u001b[0m\n",
      "\u001b[34m{'loss': 0.9178, 'grad_norm': 0.9808615446090698, 'learning_rate': 0.0005132743362831858, 'epoch': 0.5}\u001b[0m\n",
      "\u001b[34mStep 118: Loss = 0.9178\u001b[0m\n",
      "\u001b[34m{'loss': 0.8875, 'grad_norm': 0.9353005290031433, 'learning_rate': 0.0005088495575221239, 'epoch': 0.51}\u001b[0m\n",
      "\u001b[34mStep 119: Loss = 0.8875\u001b[0m\n",
      "\u001b[34m{'loss': 0.9741, 'grad_norm': 0.8681107759475708, 'learning_rate': 0.000504424778761062, 'epoch': 0.51}\u001b[0m\n",
      "\u001b[34mStep 120: Loss = 0.9741\u001b[0m\n",
      "\u001b[34m{'loss': 0.9906, 'grad_norm': 0.8457785844802856, 'learning_rate': 0.0005, 'epoch': 0.52}\u001b[0m\n",
      "\u001b[34mStep 121: Loss = 0.9906\u001b[0m\n",
      "\u001b[34m{'loss': 0.9378, 'grad_norm': 0.8549975752830505, 'learning_rate': 0.000495575221238938, 'epoch': 0.52}\u001b[0m\n",
      "\u001b[34mStep 122: Loss = 0.9378\u001b[0m\n",
      "\u001b[34m{'loss': 0.8872, 'grad_norm': 0.8217984437942505, 'learning_rate': 0.0004911504424778762, 'epoch': 0.52}\u001b[0m\n",
      "\u001b[34mStep 123: Loss = 0.8872\u001b[0m\n",
      "\u001b[34m{'loss': 0.9005, 'grad_norm': 0.947526752948761, 'learning_rate': 0.0004867256637168142, 'epoch': 0.53}\u001b[0m\n",
      "\u001b[34mStep 124: Loss = 0.9005\u001b[0m\n",
      "\u001b[34m{'loss': 0.9089, 'grad_norm': 0.817709743976593, 'learning_rate': 0.0004823008849557522, 'epoch': 0.53}\u001b[0m\n",
      "\u001b[34mStep 125: Loss = 0.9089\u001b[0m\n",
      "\u001b[34m{'loss': 0.8833, 'grad_norm': 0.8755784630775452, 'learning_rate': 0.0004778761061946903, 'epoch': 0.54}\u001b[0m\n",
      "\u001b[34mStep 126: Loss = 0.8833\u001b[0m\n",
      "\u001b[34m{'loss': 0.9023, 'grad_norm': 0.8673571944236755, 'learning_rate': 0.00047345132743362834, 'epoch': 0.54}\u001b[0m\n",
      "\u001b[34mStep 127: Loss = 0.9023\u001b[0m\n",
      "\u001b[34m{'loss': 0.9096, 'grad_norm': 0.8685963749885559, 'learning_rate': 0.0004690265486725664, 'epoch': 0.55}\u001b[0m\n",
      "\u001b[34mStep 128: Loss = 0.9096\u001b[0m\n",
      "\u001b[34m{'loss': 0.9368, 'grad_norm': 0.8365863561630249, 'learning_rate': 0.00046460176991150443, 'epoch': 0.55}\u001b[0m\n",
      "\u001b[34mStep 129: Loss = 0.9368\u001b[0m\n",
      "\u001b[34m{'loss': 0.9749, 'grad_norm': 0.8278864026069641, 'learning_rate': 0.0004601769911504425, 'epoch': 0.55}\u001b[0m\n",
      "\u001b[34mStep 130: Loss = 0.9749\u001b[0m\n",
      "\u001b[34m{'loss': 0.8734, 'grad_norm': 0.8657603859901428, 'learning_rate': 0.0004557522123893805, 'epoch': 0.56}\u001b[0m\n",
      "\u001b[34mStep 131: Loss = 0.8734\u001b[0m\n",
      "\u001b[34m{'loss': 0.858, 'grad_norm': 0.8965367078781128, 'learning_rate': 0.0004513274336283186, 'epoch': 0.56}\u001b[0m\n",
      "\u001b[34mStep 132: Loss = 0.8580\u001b[0m\n",
      "\u001b[34m{'loss': 0.9701, 'grad_norm': 0.8369291424751282, 'learning_rate': 0.0004469026548672566, 'epoch': 0.57}\u001b[0m\n",
      "\u001b[34mStep 133: Loss = 0.9701\u001b[0m\n",
      "\u001b[34m{'loss': 0.8992, 'grad_norm': 0.8021364808082581, 'learning_rate': 0.00044247787610619474, 'epoch': 0.57}\u001b[0m\n",
      "\u001b[34mStep 134: Loss = 0.8992\u001b[0m\n",
      "\u001b[34m{'loss': 0.8255, 'grad_norm': 0.8529418706893921, 'learning_rate': 0.00043805309734513276, 'epoch': 0.58}\u001b[0m\n",
      "\u001b[34mStep 135: Loss = 0.8255\u001b[0m\n",
      "\u001b[34m{'loss': 0.8672, 'grad_norm': 0.9010443091392517, 'learning_rate': 0.00043362831858407083, 'epoch': 0.58}\u001b[0m\n",
      "\u001b[34mStep 136: Loss = 0.8672\u001b[0m\n",
      "\u001b[34m{'loss': 0.8825, 'grad_norm': 0.7646540403366089, 'learning_rate': 0.00042920353982300885, 'epoch': 0.58}\u001b[0m\n",
      "\u001b[34mStep 137: Loss = 0.8825\u001b[0m\n",
      "\u001b[34m{'loss': 0.8891, 'grad_norm': 1.012496829032898, 'learning_rate': 0.0004247787610619469, 'epoch': 0.59}\u001b[0m\n",
      "\u001b[34mStep 138: Loss = 0.8891\u001b[0m\n",
      "\u001b[34m{'loss': 0.863, 'grad_norm': 0.8152198195457458, 'learning_rate': 0.00042035398230088494, 'epoch': 0.59}\u001b[0m\n",
      "\u001b[34mStep 139: Loss = 0.8630\u001b[0m\n",
      "\u001b[34m{'loss': 0.8862, 'grad_norm': 1.0258309841156006, 'learning_rate': 0.000415929203539823, 'epoch': 0.6}\u001b[0m\n",
      "\u001b[34mStep 140: Loss = 0.8862\u001b[0m\n",
      "\u001b[34m{'loss': 0.9099, 'grad_norm': 0.8385304808616638, 'learning_rate': 0.00041150442477876103, 'epoch': 0.6}\u001b[0m\n",
      "\u001b[34mStep 141: Loss = 0.9099\u001b[0m\n",
      "\u001b[34m{'loss': 0.8469, 'grad_norm': 0.9119709134101868, 'learning_rate': 0.00040707964601769916, 'epoch': 0.61}\u001b[0m\n",
      "\u001b[34mStep 142: Loss = 0.8469\u001b[0m\n",
      "\u001b[34m{'loss': 0.8407, 'grad_norm': 0.8937882781028748, 'learning_rate': 0.0004026548672566372, 'epoch': 0.61}\u001b[0m\n",
      "\u001b[34mStep 143: Loss = 0.8407\u001b[0m\n",
      "\u001b[34m{'loss': 0.8837, 'grad_norm': 0.8991223573684692, 'learning_rate': 0.00039823008849557525, 'epoch': 0.61}\u001b[0m\n",
      "\u001b[34mStep 144: Loss = 0.8837\u001b[0m\n",
      "\u001b[34m{'loss': 0.8713, 'grad_norm': 0.8138335943222046, 'learning_rate': 0.00039380530973451327, 'epoch': 0.62}\u001b[0m\n",
      "\u001b[34mStep 145: Loss = 0.8713\u001b[0m\n",
      "\u001b[34m{'loss': 0.8815, 'grad_norm': 0.7721114754676819, 'learning_rate': 0.00038938053097345134, 'epoch': 0.62}\u001b[0m\n",
      "\u001b[34mStep 146: Loss = 0.8815\u001b[0m\n",
      "\u001b[34m{'loss': 0.8348, 'grad_norm': 0.8964329957962036, 'learning_rate': 0.00038495575221238936, 'epoch': 0.63}\u001b[0m\n",
      "\u001b[34mStep 147: Loss = 0.8348\u001b[0m\n",
      "\u001b[34m{'loss': 0.8901, 'grad_norm': 0.824778139591217, 'learning_rate': 0.00038053097345132743, 'epoch': 0.63}\u001b[0m\n",
      "\u001b[34mStep 148: Loss = 0.8901\u001b[0m\n",
      "\u001b[34m{'loss': 0.8119, 'grad_norm': 0.8837280869483948, 'learning_rate': 0.00037610619469026545, 'epoch': 0.64}\u001b[0m\n",
      "\u001b[34mStep 149: Loss = 0.8119\u001b[0m\n",
      "\u001b[34m{'loss': 0.885, 'grad_norm': 0.8630686402320862, 'learning_rate': 0.0003716814159292036, 'epoch': 0.64}\u001b[0m\n",
      "\u001b[34mStep 150: Loss = 0.8850\u001b[0m\n",
      "\u001b[34m{'loss': 0.8518, 'grad_norm': 0.8433468341827393, 'learning_rate': 0.0003672566371681416, 'epoch': 0.64}\u001b[0m\n",
      "\u001b[34mStep 151: Loss = 0.8518\u001b[0m\n",
      "\u001b[34m{'loss': 0.8708, 'grad_norm': 0.799811840057373, 'learning_rate': 0.00036283185840707967, 'epoch': 0.65}\u001b[0m\n",
      "\u001b[34mStep 152: Loss = 0.8708\u001b[0m\n",
      "\u001b[34m{'loss': 0.8134, 'grad_norm': 0.8824604153633118, 'learning_rate': 0.0003584070796460177, 'epoch': 0.65}\u001b[0m\n",
      "\u001b[34mStep 153: Loss = 0.8134\u001b[0m\n",
      "\u001b[34m{'loss': 0.8594, 'grad_norm': 0.8749393224716187, 'learning_rate': 0.00035398230088495576, 'epoch': 0.66}\u001b[0m\n",
      "\u001b[34mStep 154: Loss = 0.8594\u001b[0m\n",
      "\u001b[34m{'loss': 0.9138, 'grad_norm': 0.8498300313949585, 'learning_rate': 0.0003495575221238938, 'epoch': 0.66}\u001b[0m\n",
      "\u001b[34mStep 155: Loss = 0.9138\u001b[0m\n",
      "\u001b[34m{'loss': 0.9149, 'grad_norm': 0.8080991506576538, 'learning_rate': 0.00034513274336283185, 'epoch': 0.67}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train_input = 's3://secludy-public-listing/costco_emails_formatted.jsonl'\n",
    "\n",
    "estimator.fit({'training': train_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae3b53b-7c42-45d2-91d5-8e51e758c303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
