{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cf7fc5-47e8-4703-9f75-d746d4897d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DP Fine-tune, and deploy a custom LLM model using Secludy PII-Free Synthetic Text Replicas Algorithm from AWS Marketplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d17e79a-6729-4289-b07b-84fc3b54700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pre-requisites\n",
    "Note: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "\n",
    "Ensure that IAM role used has AmazonSageMakerFullAccess\n",
    "\n",
    "Some hands-on experience using Amazon SageMaker.\n",
    "\n",
    "To use this algorithm successfully, ensure that:\n",
    "\n",
    "Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used:\n",
    "\n",
    "aws-marketplace:ViewSubscriptions\n",
    "\n",
    "aws-marketplace:Unsubscribe\n",
    "\n",
    "aws-marketplace:Subscribe\n",
    "\n",
    "or your AWS account has a subscription to For Seller to update:Secludy PII-Free Synthetic Text Replicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eab5082-70d5-4890-b8a4-034b097da208",
   "metadata": {},
   "outputs": [],
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2941ca89-ef36-49aa-9f79-ac155912f235",
   "metadata": {},
   "source": [
    "To subscribe to the algorithm: \n",
    "1. Open the algorithm listing page For Seller to update:Secludy PII-Free Synthetic Text Replicas.\n",
    "2. On the AWS Marketplace listing, click on Continue to subscribe button.\n",
    "3. On the Subscribe to this software page, review and click on “Accept Offer” if you agree with EULA, pricing, and support terms.\n",
    "4. Once you click on Continue to configuration button and then choose a region, you will see a Product Arn. This is the algorithm ARN that you need to specify while training a custom ML model. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d715101b-4fe4-43c4-a56d-f750889e0cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_arn = \"<Customer to specify algorithm ARN corresponding to their AWS region>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5be185-dad6-4dd7-bdae-54e227f55eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5688a8e2-731c-44d8-93cd-bdfc1bd86602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/28/25 04:48:25] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1075\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1075</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/28/25 04:48:25]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=53940;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=528215;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1075\u001b\\\u001b[2m1075\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1075\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1075</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=401018;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=414853;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1075\u001b\\\u001b[2m1075\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sagemaker\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86d59966-3e56-4dd8-a415-533cab9200ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::992382599914:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a854dfa6-a7ee-4355-8b94-4b1c8473096b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/28/25 04:48:46] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1075\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1075</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/28/25 04:48:46]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=906899;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=705369;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1075\u001b\\\u001b[2m1075\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import boto3\n",
    "session = boto3.Session(region_name='us-east-1')\n",
    "sagemaker_session = sagemaker.Session(boto_session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c30f2385-6577-4f71-9d5f-3e519f20131e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-us-east-1-992382599914'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket = sagemaker_session.default_bucket()\n",
    "bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da57fc5-d3fd-47a5-95a3-2d42ece78a5b",
   "metadata": {},
   "source": [
    "# Buyer need to update S3 output location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "723621c9-7115-433e-bf1d-5dd6d335c37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_location = \"s3://{}/<For seller to Update:Update a unique prefix>/{}\".format(\n",
    "#     bucket, \"output\"\n",
    "# )\n",
    "output_location = \"s3://secludy-public-listing/prod listing out/buyer-test/\".format(\n",
    "    bucket, \"output\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f6377d-9670-42dd-be83-f5e1c0991764",
   "metadata": {},
   "source": [
    "# Define hyperparameters ,update the prompt tailer to your use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1375cd7b-041f-42bb-a86a-28098f697189",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hyperparameters = {  \n",
    "    \"epochs\": \"1\",\n",
    "        \"batch_size\": \"1\",\n",
    "        \"learning_rate\": \"0.001\",\n",
    "        \"grad_accum_steps\": \"16\",\n",
    "        \"epsilon\": \"8.0\",\n",
    "        \"max_seq_length\": \"512\",\n",
    "        \"instruction\": \"Classify the following email content into its appropriate category based on its content.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "463848fd-fa05-4d34-bfda-b4952bc86683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import AlgorithmEstimator\n",
    "estimator = AlgorithmEstimator(\n",
    "algorithm_arn='arn:aws:sagemaker:us-east-1:865070037744:algorithm/dp-synthetic-data-generation-v-30e04e08e851391b9f69a7bb0d8e2033',\n",
    "role=role,\n",
    "instance_count=1,\n",
    "instance_type='ml.g5.xlarge',\n",
    "sagemaker_session=sagemaker_session,\n",
    "   output_path = output_location,\n",
    "    hyperparameters=hyperparameters,\n",
    "base_job_name='privacy-protective-synthetic-data-generation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5adaa2-0ea7-49cb-9c34-ab1f0a26c71c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/28/25 06:16:39] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py#90\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">90</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/28/25 06:16:39]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=321432;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=667306;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py#90\u001b\\\u001b[2m90\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training-job with name:                                       <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#1042\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         privacy-protective-synthetic-data-gener-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-01-28-06-16-39-177        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training-job with name:                                       \u001b]8;id=456638;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=918632;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#1042\u001b\\\u001b[2m1042\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         privacy-protective-synthetic-data-gener-\u001b[1;36m2025\u001b[0m-01-28-06-16-39-177        \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-28 06:16:39 Starting - Starting the training job...\n",
      "..25-01-28 06:17:04 Starting - Preparing the instances for training.\n",
      "..25-01-28 06:17:35 Downloading - Downloading input data.\n",
      "................................................................................\n",
      ".\u001b[34mPython 3.10.16\u001b[0mning - Training image download completed. Training in progress..\n",
      "\u001b[34mPackage                 Version\u001b[0m\n",
      "\u001b[34m----------------------- ------------\u001b[0m\n",
      "\u001b[34mabsl-py                 2.1.0\u001b[0m\n",
      "\u001b[34maccelerate              1.3.0\u001b[0m\n",
      "\u001b[34maiohappyeyeballs        2.4.4\u001b[0m\n",
      "\u001b[34maiohttp                 3.11.11\u001b[0m\n",
      "\u001b[34maiosignal               1.3.2\u001b[0m\n",
      "\u001b[34mannotated-types         0.7.0\u001b[0m\n",
      "\u001b[34masync-timeout           5.0.1\u001b[0m\n",
      "\u001b[34mattrs                   24.3.0\u001b[0m\n",
      "\u001b[34mbitsandbytes            0.45.0\u001b[0m\n",
      "\u001b[34mcertifi                 2022.12.7\u001b[0m\n",
      "\u001b[34mcffi                    1.17.1\u001b[0m\n",
      "\u001b[34mcharset-normalizer      2.1.1\u001b[0m\n",
      "\u001b[34mclick                   8.1.8\u001b[0m\n",
      "\u001b[34mcryptography            44.0.0\u001b[0m\n",
      "\u001b[34mdatasets                3.2.0\u001b[0m\n",
      "\u001b[34mdill                    0.3.8\u001b[0m\n",
      "\u001b[34mdocker-pycreds          0.4.0\u001b[0m\n",
      "\u001b[34meinops                  0.8.0\u001b[0m\n",
      "\u001b[34mfilelock                3.13.1\u001b[0m\n",
      "\u001b[34mflash-attn              2.7.3\u001b[0m\n",
      "\u001b[34mfrozenlist              1.5.0\u001b[0m\n",
      "\u001b[34mfsspec                  2024.2.0\u001b[0m\n",
      "\u001b[34mgitdb                   4.0.12\u001b[0m\n",
      "\u001b[34mGitPython               3.1.44\u001b[0m\n",
      "\u001b[34mgrpcio                  1.69.0\u001b[0m\n",
      "\u001b[34mhuggingface-hub         0.27.1\u001b[0m\n",
      "\u001b[34midna                    3.4\u001b[0m\n",
      "\u001b[34mJinja2                  3.1.3\u001b[0m\n",
      "\u001b[34mMarkdown                3.7\u001b[0m\n",
      "\u001b[34mmarkdown-it-py          3.0.0\u001b[0m\n",
      "\u001b[34mMarkupSafe              2.1.5\u001b[0m\n",
      "\u001b[34mmdurl                   0.1.2\u001b[0m\n",
      "\u001b[34mmpmath                  1.3.0\u001b[0m\n",
      "\u001b[34mmultidict               6.1.0\u001b[0m\n",
      "\u001b[34mmultiprocess            0.70.16\u001b[0m\n",
      "\u001b[34mnetworkx                3.2.1\u001b[0m\n",
      "\u001b[34mnumpy                   1.26.3\u001b[0m\n",
      "\u001b[34mpackaging               24.2\u001b[0m\n",
      "\u001b[34mpandas                  2.2.3\u001b[0m\n",
      "\u001b[34mpeft                    0.14.0\u001b[0m\n",
      "\u001b[34mpillow                  10.2.0\u001b[0m\n",
      "\u001b[34mpip                     24.2\u001b[0m\n",
      "\u001b[34mplatformdirs            4.3.6\u001b[0m\n",
      "\u001b[34mpropcache               0.2.1\u001b[0m\n",
      "\u001b[34mprotobuf                5.29.3\u001b[0m\n",
      "\u001b[34mpsutil                  6.1.1\u001b[0m\n",
      "\u001b[34mpyarrow                 19.0.0\u001b[0m\n",
      "\u001b[34mpycparser               2.22\u001b[0m\n",
      "\u001b[34mpydantic                2.10.5\u001b[0m\n",
      "\u001b[34mpydantic_core           2.27.2\u001b[0m\n",
      "\u001b[34mPygments                2.19.1\u001b[0m\n",
      "\u001b[34mpython-dateutil         2.9.0.post0\u001b[0m\n",
      "\u001b[34mpython-dotenv           1.0.1\u001b[0m\n",
      "\u001b[34mpytz                    2024.2\u001b[0m\n",
      "\u001b[34mPyYAML                  6.0.2\u001b[0m\n",
      "\u001b[34mregex                   2024.11.6\u001b[0m\n",
      "\u001b[34mrequests                2.32.3\u001b[0m\n",
      "\u001b[34mrich                    13.9.4\u001b[0m\n",
      "\u001b[34msafetensors             0.5.2\u001b[0m\n",
      "\u001b[34mscipy                   1.15.1\u001b[0m\n",
      "\u001b[34msentencepiece           0.2.0\u001b[0m\n",
      "\u001b[34msentry-sdk              2.20.0\u001b[0m\n",
      "\u001b[34msetproctitle            1.3.4\u001b[0m\n",
      "\u001b[34msetuptools              75.1.0\u001b[0m\n",
      "\u001b[34msix                     1.17.0\u001b[0m\n",
      "\u001b[34msmmap                   5.0.2\u001b[0m\n",
      "\u001b[34msympy                   1.13.1\u001b[0m\n",
      "\u001b[34mtensorboard             2.18.0\u001b[0m\n",
      "\u001b[34mtensorboard-data-server 0.7.2\u001b[0m\n",
      "\u001b[34mtokenizers              0.21.0\u001b[0m\n",
      "\u001b[34mtorch                   2.1.1+cu121\u001b[0m\n",
      "\u001b[34mtorchaudio              2.1.1+cu121\u001b[0m\n",
      "\u001b[34mtorchvision             0.16.1+cu121\u001b[0m\n",
      "\u001b[34mtqdm                    4.67.1\u001b[0m\n",
      "\u001b[34mtransformers            4.48.1\u001b[0m\n",
      "\u001b[34mtriton                  2.1.0\u001b[0m\n",
      "\u001b[34mtrl                     0.13.0\u001b[0m\n",
      "\u001b[34mtyping_extensions       4.12.2\u001b[0m\n",
      "\u001b[34mtzdata                  2025.1\u001b[0m\n",
      "\u001b[34murllib3                 1.26.13\u001b[0m\n",
      "\u001b[34mwandb                   0.19.4\u001b[0m\n",
      "\u001b[34mWerkzeug                3.1.3\u001b[0m\n",
      "\u001b[34mwheel                   0.44.0\u001b[0m\n",
      "\u001b[34mxxhash                  3.5.0\u001b[0m\n",
      "\u001b[34myarl                    1.18.3\u001b[0m\n",
      "\u001b[34mStarting training...\u001b[0m\n",
      "\u001b[34mTraining data directory: /opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mModel directory: /opt/ml/model\u001b[0m\n",
      "\u001b[34mReloading base model with quantization...\u001b[0m\n",
      "\u001b[34m/opt/conda/envs/fast_dp_dev/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mLoading and processing dataset...\u001b[0m\n",
      "\u001b[34mFound 1 JSONL files in /opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mUsing instruction: Classify the following email content into its appropriate category based on its content.\u001b[0m\n",
      "\u001b[34mProcessing costco_emails_formatted.jsonl...\u001b[0m\n",
      "\u001b[34mTotal processed entries: 4660\u001b[0m\n",
      "\u001b[34mSplitting dataset...\u001b[0m\n",
      "\u001b[34mDataset sizes - Train: 3728, Validation: 932\u001b[0m\n",
      "\u001b[34m***** SINGLE RUN *****\u001b[0m\n",
      "\u001b[34m/opt/program/fast_dp_trainer.py:30: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `FastDPTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\u001b[0m\n",
      "\u001b[34m/opt/conda/envs/fast_dp_dev/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m#015Map:   0%|          | 0/3728 [00:00<?, ? examples/s]#015Map:  27%|██▋       | 1000/3728 [00:00<00:00, 5897.15 examples/s]#015Map:  54%|█████▎    | 2000/3728 [00:00<00:00, 6148.00 examples/s]#015Map:  80%|████████  | 3000/3728 [00:00<00:00, 6425.57 examples/s]#015Map: 100%|██████████| 3728/3728 [00:00<00:00, 6460.81 examples/s]#015Map: 100%|██████████| 3728/3728 [00:00<00:00, 6297.43 examples/s]\u001b[0m\n",
      "\u001b[34m#015Map:   0%|          | 0/932 [00:00<?, ? examples/s]#015Map: 100%|██████████| 932/932 [00:00<00:00, 7005.63 examples/s]#015Map: 100%|██████████| 932/932 [00:00<00:00, 6857.00 examples/s]\u001b[0m\n",
      "\u001b[34mStarting training...\u001b[0m\n",
      "\u001b[34mNumber of trainable components:  392 ; Number of trainable layers:  392\u001b[0m\n",
      "\u001b[34m>>>>>>>>>>>>>>>>> Applying  automatic  per-sample gradient clipping.\u001b[0m\n",
      "\u001b[34m>>>>>>>>>>>>>>>>> Block heads for per-sample gradient clipping are defined as: ['base_model.model.model.layers.0.self_attn.q_proj.lora_A.default']\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/233 [00:00<?, ?it/s]/opt/conda/envs/fast_dp_dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\u001b[0m\n",
      "\u001b[34m{'loss': 2.4009, 'grad_norm': 1.4098109006881714, 'learning_rate': 0.00014285714285714284, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34mStep 2: Loss = 2.4009\u001b[0m\n",
      "\u001b[34m{'loss': 2.3535, 'grad_norm': 1.3968547582626343, 'learning_rate': 0.0002857142857142857, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34mStep 3: Loss = 2.3535\u001b[0m\n",
      "\u001b[34m{'loss': 2.3974, 'grad_norm': 1.4039863348007202, 'learning_rate': 0.00042857142857142855, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34mStep 4: Loss = 2.3974\u001b[0m\n",
      "\u001b[34m{'loss': 2.3704, 'grad_norm': 1.4410611391067505, 'learning_rate': 0.0005714285714285714, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34mStep 5: Loss = 2.3704\u001b[0m\n",
      "\u001b[34m{'loss': 2.3283, 'grad_norm': 1.4178719520568848, 'learning_rate': 0.0007142857142857143, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34mStep 6: Loss = 2.3283\u001b[0m\n",
      "\u001b[34m{'loss': 2.3566, 'grad_norm': 1.4010244607925415, 'learning_rate': 0.0008571428571428571, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34mStep 7: Loss = 2.3566\u001b[0m\n",
      "\u001b[34m{'loss': 2.2792, 'grad_norm': 1.4975212812423706, 'learning_rate': 0.001, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34mStep 8: Loss = 2.2792\u001b[0m\n",
      "\u001b[34m{'loss': 2.2335, 'grad_norm': 1.4937913417816162, 'learning_rate': 0.000995575221238938, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34mStep 9: Loss = 2.2335\u001b[0m\n",
      "\u001b[34m{'loss': 2.2273, 'grad_norm': 1.5484271049499512, 'learning_rate': 0.000991150442477876, 'epoch': 0.04}\u001b[0m\n",
      "\u001b[34mStep 10: Loss = 2.2273\u001b[0m\n",
      "\u001b[34m{'loss': 2.1699, 'grad_norm': 1.6027448177337646, 'learning_rate': 0.000986725663716814, 'epoch': 0.04}\u001b[0m\n",
      "\u001b[34mStep 11: Loss = 2.1699\u001b[0m\n",
      "\u001b[34m{'loss': 2.1734, 'grad_norm': 1.72893226146698, 'learning_rate': 0.0009823008849557523, 'epoch': 0.05}\u001b[0m\n",
      "\u001b[34mStep 12: Loss = 2.1734\u001b[0m\n",
      "\u001b[34m{'loss': 2.115, 'grad_norm': 1.7969094514846802, 'learning_rate': 0.0009778761061946903, 'epoch': 0.05}\u001b[0m\n",
      "\u001b[34mStep 13: Loss = 2.1150\u001b[0m\n",
      "\u001b[34m{'loss': 2.0842, 'grad_norm': 1.7367030382156372, 'learning_rate': 0.0009734513274336283, 'epoch': 0.06}\u001b[0m\n",
      "\u001b[34mStep 14: Loss = 2.0842\u001b[0m\n",
      "\u001b[34m{'loss': 2.0217, 'grad_norm': 1.670121192932129, 'learning_rate': 0.0009690265486725664, 'epoch': 0.06}\u001b[0m\n",
      "\u001b[34mStep 15: Loss = 2.0217\u001b[0m\n",
      "\u001b[34m{'loss': 2.0046, 'grad_norm': 1.63031804561615, 'learning_rate': 0.0009646017699115044, 'epoch': 0.06}\u001b[0m\n",
      "\u001b[34mStep 16: Loss = 2.0046\u001b[0m\n",
      "\u001b[34m{'loss': 1.993, 'grad_norm': 1.540791630744934, 'learning_rate': 0.0009601769911504425, 'epoch': 0.07}\u001b[0m\n",
      "\u001b[34mStep 17: Loss = 1.9930\u001b[0m\n",
      "\u001b[34m{'loss': 1.9152, 'grad_norm': 1.4714925289154053, 'learning_rate': 0.0009557522123893806, 'epoch': 0.07}\u001b[0m\n",
      "\u001b[34mStep 18: Loss = 1.9152\u001b[0m\n",
      "\u001b[34m{'loss': 1.9054, 'grad_norm': 1.4581881761550903, 'learning_rate': 0.0009513274336283187, 'epoch': 0.08}\u001b[0m\n",
      "\u001b[34mStep 19: Loss = 1.9054\u001b[0m\n",
      "\u001b[34m{'loss': 1.8497, 'grad_norm': 1.420304298400879, 'learning_rate': 0.0009469026548672567, 'epoch': 0.08}\u001b[0m\n",
      "\u001b[34mStep 20: Loss = 1.8497\u001b[0m\n",
      "\u001b[34m{'loss': 1.8378, 'grad_norm': 1.363046407699585, 'learning_rate': 0.0009424778761061947, 'epoch': 0.09}\u001b[0m\n",
      "\u001b[34mStep 21: Loss = 1.8378\u001b[0m\n",
      "\u001b[34m{'loss': 1.8225, 'grad_norm': 1.06986403465271, 'learning_rate': 0.0009380530973451328, 'epoch': 0.09}\u001b[0m\n",
      "\u001b[34mStep 22: Loss = 1.8225\u001b[0m\n",
      "\u001b[34m{'loss': 1.7771, 'grad_norm': 0.9443598389625549, 'learning_rate': 0.0009336283185840708, 'epoch': 0.09}\u001b[0m\n",
      "\u001b[34mStep 23: Loss = 1.7771\u001b[0m\n",
      "\u001b[34m{'loss': 1.7802, 'grad_norm': 0.9292798042297363, 'learning_rate': 0.0009292035398230089, 'epoch': 0.1}\u001b[0m\n",
      "\u001b[34mStep 24: Loss = 1.7802\u001b[0m\n",
      "\u001b[34m{'loss': 1.7244, 'grad_norm': 0.9054421782493591, 'learning_rate': 0.0009247787610619469, 'epoch': 0.1}\u001b[0m\n",
      "\u001b[34mStep 25: Loss = 1.7244\u001b[0m\n",
      "\u001b[34m{'loss': 1.7913, 'grad_norm': 0.8925702571868896, 'learning_rate': 0.000920353982300885, 'epoch': 0.11}\u001b[0m\n",
      "\u001b[34mStep 26: Loss = 1.7913\u001b[0m\n",
      "\u001b[34m{'loss': 1.7914, 'grad_norm': 0.916957437992096, 'learning_rate': 0.000915929203539823, 'epoch': 0.11}\u001b[0m\n",
      "\u001b[34mStep 27: Loss = 1.7914\u001b[0m\n",
      "\u001b[34m{'loss': 1.7265, 'grad_norm': 0.8910645246505737, 'learning_rate': 0.000911504424778761, 'epoch': 0.12}\u001b[0m\n",
      "\u001b[34mStep 28: Loss = 1.7265\u001b[0m\n",
      "\u001b[34m{'loss': 1.7391, 'grad_norm': 0.8823187351226807, 'learning_rate': 0.0009070796460176991, 'epoch': 0.12}\u001b[0m\n",
      "\u001b[34mStep 29: Loss = 1.7391\u001b[0m\n",
      "\u001b[34m{'loss': 1.6869, 'grad_norm': 0.9225029349327087, 'learning_rate': 0.0009026548672566372, 'epoch': 0.12}\u001b[0m\n",
      "\u001b[34mStep 30: Loss = 1.6869\u001b[0m\n",
      "\u001b[34m{'loss': 1.6692, 'grad_norm': 0.8729566931724548, 'learning_rate': 0.0008982300884955752, 'epoch': 0.13}\u001b[0m\n",
      "\u001b[34mStep 31: Loss = 1.6692\u001b[0m\n",
      "\u001b[34m{'loss': 1.6762, 'grad_norm': 0.8898665308952332, 'learning_rate': 0.0008938053097345132, 'epoch': 0.13}\u001b[0m\n",
      "\u001b[34mStep 32: Loss = 1.6762\u001b[0m\n",
      "\u001b[34m{'loss': 1.6914, 'grad_norm': 0.9264739155769348, 'learning_rate': 0.0008893805309734513, 'epoch': 0.14}\u001b[0m\n",
      "\u001b[34mStep 33: Loss = 1.6914\u001b[0m\n",
      "\u001b[34m{'loss': 1.6956, 'grad_norm': 0.8698856830596924, 'learning_rate': 0.0008849557522123895, 'epoch': 0.14}\u001b[0m\n",
      "\u001b[34mStep 34: Loss = 1.6956\u001b[0m\n",
      "\u001b[34m{'loss': 1.6459, 'grad_norm': 0.9507430195808411, 'learning_rate': 0.0008805309734513275, 'epoch': 0.15}\u001b[0m\n",
      "\u001b[34mStep 35: Loss = 1.6459\u001b[0m\n",
      "\u001b[34m{'loss': 1.6078, 'grad_norm': 0.9161510467529297, 'learning_rate': 0.0008761061946902655, 'epoch': 0.15}\u001b[0m\n",
      "\u001b[34mStep 36: Loss = 1.6078\u001b[0m\n",
      "\u001b[34m{'loss': 1.5894, 'grad_norm': 0.8362436890602112, 'learning_rate': 0.0008716814159292035, 'epoch': 0.15}\u001b[0m\n",
      "\u001b[34mStep 37: Loss = 1.5894\u001b[0m\n",
      "\u001b[34m{'loss': 1.5655, 'grad_norm': 0.9414142966270447, 'learning_rate': 0.0008672566371681417, 'epoch': 0.16}\u001b[0m\n",
      "\u001b[34mStep 38: Loss = 1.5655\u001b[0m\n",
      "\u001b[34m{'loss': 1.5838, 'grad_norm': 0.947796642780304, 'learning_rate': 0.0008628318584070797, 'epoch': 0.16}\u001b[0m\n",
      "\u001b[34mStep 39: Loss = 1.5838\u001b[0m\n",
      "\u001b[34m{'loss': 1.595, 'grad_norm': 0.9322019815444946, 'learning_rate': 0.0008584070796460177, 'epoch': 0.17}\u001b[0m\n",
      "\u001b[34mStep 40: Loss = 1.5950\u001b[0m\n",
      "\u001b[34m{'loss': 1.5033, 'grad_norm': 0.9724403023719788, 'learning_rate': 0.0008539823008849557, 'epoch': 0.17}\u001b[0m\n",
      "\u001b[34mStep 41: Loss = 1.5033\u001b[0m\n",
      "\u001b[34m{'loss': 1.5391, 'grad_norm': 0.9693736433982849, 'learning_rate': 0.0008495575221238938, 'epoch': 0.18}\u001b[0m\n",
      "\u001b[34mStep 42: Loss = 1.5391\u001b[0m\n",
      "\u001b[34m{'loss': 1.5004, 'grad_norm': 1.0643633604049683, 'learning_rate': 0.0008451327433628319, 'epoch': 0.18}\u001b[0m\n",
      "\u001b[34mStep 43: Loss = 1.5004\u001b[0m\n",
      "\u001b[34m{'loss': 1.5613, 'grad_norm': 1.0188454389572144, 'learning_rate': 0.0008407079646017699, 'epoch': 0.18}\u001b[0m\n",
      "\u001b[34mStep 44: Loss = 1.5613\u001b[0m\n",
      "\u001b[34m{'loss': 1.4894, 'grad_norm': 1.0261648893356323, 'learning_rate': 0.0008362831858407079, 'epoch': 0.19}\u001b[0m\n",
      "\u001b[34mStep 45: Loss = 1.4894\u001b[0m\n",
      "\u001b[34m{'loss': 1.437, 'grad_norm': 1.0999504327774048, 'learning_rate': 0.000831858407079646, 'epoch': 0.19}\u001b[0m\n",
      "\u001b[34mStep 46: Loss = 1.4370\u001b[0m\n",
      "\u001b[34m{'loss': 1.4334, 'grad_norm': 1.0998942852020264, 'learning_rate': 0.000827433628318584, 'epoch': 0.2}\u001b[0m\n",
      "\u001b[34mStep 47: Loss = 1.4334\u001b[0m\n",
      "\u001b[34m{'loss': 1.4307, 'grad_norm': 1.1035492420196533, 'learning_rate': 0.0008230088495575221, 'epoch': 0.2}\u001b[0m\n",
      "\u001b[34mStep 48: Loss = 1.4307\u001b[0m\n",
      "\u001b[34m{'loss': 1.4604, 'grad_norm': 1.1862856149673462, 'learning_rate': 0.0008185840707964603, 'epoch': 0.21}\u001b[0m\n",
      "\u001b[34mStep 49: Loss = 1.4604\u001b[0m\n",
      "\u001b[34m{'loss': 1.4253, 'grad_norm': 1.1728531122207642, 'learning_rate': 0.0008141592920353983, 'epoch': 0.21}\u001b[0m\n",
      "\u001b[34mStep 50: Loss = 1.4253\u001b[0m\n",
      "\u001b[34m{'loss': 1.3599, 'grad_norm': 1.275278925895691, 'learning_rate': 0.0008097345132743363, 'epoch': 0.21}\u001b[0m\n",
      "\u001b[34mStep 51: Loss = 1.3599\u001b[0m\n",
      "\u001b[34m{'loss': 1.3951, 'grad_norm': 1.248653531074524, 'learning_rate': 0.0008053097345132744, 'epoch': 0.22}\u001b[0m\n",
      "\u001b[34mStep 52: Loss = 1.3951\u001b[0m\n",
      "\u001b[34m{'loss': 1.3581, 'grad_norm': 1.4117249250411987, 'learning_rate': 0.0008008849557522125, 'epoch': 0.22}\u001b[0m\n",
      "\u001b[34mStep 53: Loss = 1.3581\u001b[0m\n",
      "\u001b[34m{'loss': 1.3726, 'grad_norm': 1.2012912034988403, 'learning_rate': 0.0007964601769911505, 'epoch': 0.23}\u001b[0m\n",
      "\u001b[34mStep 54: Loss = 1.3726\u001b[0m\n",
      "\u001b[34m{'loss': 1.3313, 'grad_norm': 1.1654132604599, 'learning_rate': 0.0007920353982300885, 'epoch': 0.23}\u001b[0m\n",
      "\u001b[34mStep 55: Loss = 1.3313\u001b[0m\n",
      "\u001b[34m{'loss': 1.2847, 'grad_norm': 1.269989013671875, 'learning_rate': 0.0007876106194690265, 'epoch': 0.24}\u001b[0m\n",
      "\u001b[34mStep 56: Loss = 1.2847\u001b[0m\n",
      "\u001b[34m{'loss': 1.2958, 'grad_norm': 1.1164374351501465, 'learning_rate': 0.0007831858407079647, 'epoch': 0.24}\u001b[0m\n",
      "\u001b[34mStep 57: Loss = 1.2958\u001b[0m\n",
      "\u001b[34m{'loss': 1.3272, 'grad_norm': 1.2901959419250488, 'learning_rate': 0.0007787610619469027, 'epoch': 0.24}\u001b[0m\n",
      "\u001b[34mStep 58: Loss = 1.3272\u001b[0m\n",
      "\u001b[34m{'loss': 1.2861, 'grad_norm': 1.7707322835922241, 'learning_rate': 0.0007743362831858407, 'epoch': 0.25}\u001b[0m\n",
      "\u001b[34mStep 59: Loss = 1.2861\u001b[0m\n",
      "\u001b[34m{'loss': 1.2994, 'grad_norm': 2.134423017501831, 'learning_rate': 0.0007699115044247787, 'epoch': 0.25}\u001b[0m\n",
      "\u001b[34mStep 60: Loss = 1.2994\u001b[0m\n",
      "\u001b[34m{'loss': 1.2543, 'grad_norm': 1.986324667930603, 'learning_rate': 0.0007654867256637168, 'epoch': 0.26}\u001b[0m\n",
      "\u001b[34mStep 61: Loss = 1.2543\u001b[0m\n",
      "\u001b[34m{'loss': 1.2367, 'grad_norm': 1.1240893602371216, 'learning_rate': 0.0007610619469026549, 'epoch': 0.26}\u001b[0m\n",
      "\u001b[34mStep 62: Loss = 1.2367\u001b[0m\n",
      "\u001b[34m{'loss': 1.265, 'grad_norm': 1.11410653591156, 'learning_rate': 0.0007566371681415929, 'epoch': 0.27}\u001b[0m\n",
      "\u001b[34mStep 63: Loss = 1.2650\u001b[0m\n",
      "\u001b[34m{'loss': 1.2356, 'grad_norm': 0.911418080329895, 'learning_rate': 0.0007522123893805309, 'epoch': 0.27}\u001b[0m\n",
      "\u001b[34mStep 64: Loss = 1.2356\u001b[0m\n",
      "\u001b[34m{'loss': 1.2449, 'grad_norm': 0.8328925967216492, 'learning_rate': 0.0007477876106194691, 'epoch': 0.27}\u001b[0m\n",
      "\u001b[34mStep 65: Loss = 1.2449\u001b[0m\n",
      "\u001b[34m{'loss': 1.3013, 'grad_norm': 0.914576530456543, 'learning_rate': 0.0007433628318584072, 'epoch': 0.28}\u001b[0m\n",
      "\u001b[34mStep 66: Loss = 1.3013\u001b[0m\n",
      "\u001b[34m{'loss': 1.2739, 'grad_norm': 0.8859279155731201, 'learning_rate': 0.0007389380530973452, 'epoch': 0.28}\u001b[0m\n",
      "\u001b[34mStep 67: Loss = 1.2739\u001b[0m\n",
      "\u001b[34m{'loss': 1.2374, 'grad_norm': 1.0523165464401245, 'learning_rate': 0.0007345132743362832, 'epoch': 0.29}\u001b[0m\n",
      "\u001b[34mStep 68: Loss = 1.2374\u001b[0m\n",
      "\u001b[34m{'loss': 1.234, 'grad_norm': 0.8947208523750305, 'learning_rate': 0.0007300884955752213, 'epoch': 0.29}\u001b[0m\n",
      "\u001b[34mStep 69: Loss = 1.2340\u001b[0m\n",
      "\u001b[34m{'loss': 1.2035, 'grad_norm': 0.9666450023651123, 'learning_rate': 0.0007256637168141593, 'epoch': 0.3}\u001b[0m\n",
      "\u001b[34mStep 70: Loss = 1.2035\u001b[0m\n",
      "\u001b[34m{'loss': 1.1865, 'grad_norm': 0.9628391861915588, 'learning_rate': 0.0007212389380530974, 'epoch': 0.3}\u001b[0m\n",
      "\u001b[34mStep 71: Loss = 1.1865\u001b[0m\n",
      "\u001b[34m{'loss': 1.2198, 'grad_norm': 0.8731601238250732, 'learning_rate': 0.0007168141592920354, 'epoch': 0.3}\u001b[0m\n",
      "\u001b[34mStep 72: Loss = 1.2198\u001b[0m\n",
      "\u001b[34m{'loss': 1.2572, 'grad_norm': 0.8449949622154236, 'learning_rate': 0.0007123893805309735, 'epoch': 0.31}\u001b[0m\n",
      "\u001b[34mStep 73: Loss = 1.2572\u001b[0m\n",
      "\u001b[34m{'loss': 1.1681, 'grad_norm': 0.8850548267364502, 'learning_rate': 0.0007079646017699115, 'epoch': 0.31}\u001b[0m\n",
      "\u001b[34mStep 74: Loss = 1.1681\u001b[0m\n",
      "\u001b[34m{'loss': 1.1223, 'grad_norm': 0.8564367294311523, 'learning_rate': 0.0007035398230088495, 'epoch': 0.32}\u001b[0m\n",
      "\u001b[34mStep 75: Loss = 1.1223\u001b[0m\n",
      "\u001b[34m{'loss': 1.1769, 'grad_norm': 0.8485937714576721, 'learning_rate': 0.0006991150442477876, 'epoch': 0.32}\u001b[0m\n",
      "\u001b[34mStep 76: Loss = 1.1769\u001b[0m\n",
      "\u001b[34m{'loss': 1.1674, 'grad_norm': 0.8565574288368225, 'learning_rate': 0.0006946902654867257, 'epoch': 0.33}\u001b[0m\n",
      "\u001b[34mStep 77: Loss = 1.1674\u001b[0m\n",
      "\u001b[34m{'loss': 1.1905, 'grad_norm': 0.8706735968589783, 'learning_rate': 0.0006902654867256637, 'epoch': 0.33}\u001b[0m\n",
      "\u001b[34mStep 78: Loss = 1.1905\u001b[0m\n",
      "\u001b[34m{'loss': 1.1597, 'grad_norm': 0.8835492134094238, 'learning_rate': 0.0006858407079646017, 'epoch': 0.33}\u001b[0m\n",
      "\u001b[34mStep 79: Loss = 1.1597\u001b[0m\n",
      "\u001b[34m{'loss': 1.169, 'grad_norm': 0.9517481327056885, 'learning_rate': 0.0006814159292035397, 'epoch': 0.34}\u001b[0m\n",
      "\u001b[34mStep 80: Loss = 1.1690\u001b[0m\n",
      "\u001b[34m{'loss': 1.1518, 'grad_norm': 0.9995867013931274, 'learning_rate': 0.000676991150442478, 'epoch': 0.34}\u001b[0m\n",
      "\u001b[34mStep 81: Loss = 1.1518\u001b[0m\n",
      "\u001b[34m{'loss': 1.1639, 'grad_norm': 0.8538850545883179, 'learning_rate': 0.000672566371681416, 'epoch': 0.35}\u001b[0m\n",
      "\u001b[34mStep 82: Loss = 1.1639\u001b[0m\n",
      "\u001b[34m{'loss': 1.1707, 'grad_norm': 1.0619152784347534, 'learning_rate': 0.000668141592920354, 'epoch': 0.35}\u001b[0m\n",
      "\u001b[34mStep 83: Loss = 1.1707\u001b[0m\n",
      "\u001b[34m{'loss': 1.0879, 'grad_norm': 0.9287571907043457, 'learning_rate': 0.0006637168141592921, 'epoch': 0.36}\u001b[0m\n",
      "\u001b[34mStep 84: Loss = 1.0879\u001b[0m\n",
      "\u001b[34m{'loss': 1.1102, 'grad_norm': 0.9442043900489807, 'learning_rate': 0.0006592920353982302, 'epoch': 0.36}\u001b[0m\n",
      "\u001b[34mStep 85: Loss = 1.1102\u001b[0m\n",
      "\u001b[34m{'loss': 1.1216, 'grad_norm': 1.0370407104492188, 'learning_rate': 0.0006548672566371682, 'epoch': 0.36}\u001b[0m\n",
      "\u001b[34mStep 86: Loss = 1.1216\u001b[0m\n",
      "\u001b[34m{'loss': 1.0687, 'grad_norm': 0.961850643157959, 'learning_rate': 0.0006504424778761062, 'epoch': 0.37}\u001b[0m\n",
      "\u001b[34mStep 87: Loss = 1.0687\u001b[0m\n",
      "\u001b[34m{'loss': 1.1073, 'grad_norm': 0.9987707734107971, 'learning_rate': 0.0006460176991150443, 'epoch': 0.37}\u001b[0m\n",
      "\u001b[34mStep 88: Loss = 1.1073\u001b[0m\n",
      "\u001b[34m{'loss': 1.1458, 'grad_norm': 0.9583374261856079, 'learning_rate': 0.0006415929203539823, 'epoch': 0.38}\u001b[0m\n",
      "\u001b[34mStep 89: Loss = 1.1458\u001b[0m\n",
      "\u001b[34m{'loss': 1.0892, 'grad_norm': 0.9562974572181702, 'learning_rate': 0.0006371681415929204, 'epoch': 0.38}\u001b[0m\n",
      "\u001b[34mStep 90: Loss = 1.0892\u001b[0m\n",
      "\u001b[34m{'loss': 1.0726, 'grad_norm': 0.9667190909385681, 'learning_rate': 0.0006327433628318584, 'epoch': 0.39}\u001b[0m\n",
      "\u001b[34mStep 91: Loss = 1.0726\u001b[0m\n",
      "\u001b[34m{'loss': 1.0748, 'grad_norm': 1.0628995895385742, 'learning_rate': 0.0006283185840707965, 'epoch': 0.39}\u001b[0m\n",
      "\u001b[34mStep 92: Loss = 1.0748\u001b[0m\n",
      "\u001b[34m{'loss': 1.0506, 'grad_norm': 1.0377590656280518, 'learning_rate': 0.0006238938053097345, 'epoch': 0.39}\u001b[0m\n",
      "\u001b[34mStep 93: Loss = 1.0506\u001b[0m\n",
      "\u001b[34m{'loss': 1.0418, 'grad_norm': 1.053757905960083, 'learning_rate': 0.0006194690265486725, 'epoch': 0.4}\u001b[0m\n",
      "\u001b[34mStep 94: Loss = 1.0418\u001b[0m\n",
      "\u001b[34m{'loss': 1.0536, 'grad_norm': 1.0221678018569946, 'learning_rate': 0.0006150442477876106, 'epoch': 0.4}\u001b[0m\n",
      "\u001b[34mStep 95: Loss = 1.0536\u001b[0m\n",
      "\u001b[34m{'loss': 1.0957, 'grad_norm': 1.1512125730514526, 'learning_rate': 0.0006106194690265487, 'epoch': 0.41}\u001b[0m\n",
      "\u001b[34mStep 96: Loss = 1.0957\u001b[0m\n",
      "\u001b[34m{'loss': 1.0913, 'grad_norm': 1.0041476488113403, 'learning_rate': 0.0006061946902654868, 'epoch': 0.41}\u001b[0m\n",
      "\u001b[34mStep 97: Loss = 1.0913\u001b[0m\n",
      "\u001b[34m{'loss': 1.0166, 'grad_norm': 1.078669548034668, 'learning_rate': 0.0006017699115044248, 'epoch': 0.42}\u001b[0m\n",
      "\u001b[34mStep 98: Loss = 1.0166\u001b[0m\n",
      "\u001b[34m{'loss': 1.0122, 'grad_norm': 1.0471851825714111, 'learning_rate': 0.0005973451327433628, 'epoch': 0.42}\u001b[0m\n",
      "\u001b[34mStep 99: Loss = 1.0122\u001b[0m\n",
      "\u001b[34m{'loss': 1.0362, 'grad_norm': 0.9615678787231445, 'learning_rate': 0.000592920353982301, 'epoch': 0.42}\u001b[0m\n",
      "\u001b[34mStep 100: Loss = 1.0362\u001b[0m\n",
      "\u001b[34m{'loss': 1.0236, 'grad_norm': 1.0628297328948975, 'learning_rate': 0.000588495575221239, 'epoch': 0.43}\u001b[0m\n",
      "\u001b[34mStep 101: Loss = 1.0236\u001b[0m\n",
      "\u001b[34m{'loss': 1.0396, 'grad_norm': 1.0147632360458374, 'learning_rate': 0.000584070796460177, 'epoch': 0.43}\u001b[0m\n",
      "\u001b[34mStep 102: Loss = 1.0396\u001b[0m\n",
      "\u001b[34m{'loss': 1.0414, 'grad_norm': 1.1183717250823975, 'learning_rate': 0.000579646017699115, 'epoch': 0.44}\u001b[0m\n",
      "\u001b[34mStep 103: Loss = 1.0414\u001b[0m\n",
      "\u001b[34m{'loss': 1.0464, 'grad_norm': 1.098677635192871, 'learning_rate': 0.0005752212389380532, 'epoch': 0.44}\u001b[0m\n",
      "\u001b[34mStep 104: Loss = 1.0464\u001b[0m\n",
      "\u001b[34m{'loss': 0.965, 'grad_norm': 1.0824111700057983, 'learning_rate': 0.0005707964601769912, 'epoch': 0.45}\u001b[0m\n",
      "\u001b[34m#015  0%|          | 1/233 [00:07<28:35,  7.39s/it]#015                                               #015#015  0%|          | 1/233 [00:07<28:35,  7.39s/it]#015  1%|          | 2/233 [00:13<26:23,  6.86s/it]#015                                               #015#015  1%|          | 2/233 [00:13<26:23,  6.86s/it]#015  1%|▏         | 3/233 [00:20<25:20,  6.61s/it]#015                                               #015#015  1%|▏         | 3/233 [00:20<25:20,  6.61s/it]#015  2%|▏         | 4/233 [00:26<24:49,  6.50s/it]#015                                               #015#015  2%|▏         | 4/233 [00:26<24:49,  6.50s/it]#015  2%|▏         | 5/233 [00:32<24:30,  6.45s/it]#015                                               #015#015  2%|▏         | 5/233 [00:32<24:30,  6.45s/it]#015  3%|▎         | 6/233 [00:39<24:10,  6.39s/it]#015                                               #015#015  3%|▎         | 6/233 [00:39<24:10,  6.39s/it]#015  3%|▎         | 7/233 [00:45<24:00,  6.38s/it]#015                                               #015#015  3%|▎         | 7/233 [00:45<24:00,  6.38s/it]#015  3%|▎         | 8/233 [00:52<24:03,  6.41s/it]#015                                               #015#015  3%|▎         | 8/233 [00:52<24:03,  6.41s/it]#015  4%|▍         | 9/233 [00:58<23:53,  6.40s/it]#015                                               #015#015  4%|▍         | 9/233 [00:58<23:53,  6.40s/it]#015  4%|▍         | 10/233 [01:04<23:43,  6.38s/it]#015                                                #015#015  4%|▍         | 10/233 [01:04<23:43,  6.38s/it]#015  5%|▍         | 11/233 [01:11<23:34,  6.37s/it]#015                                                #015#015  5%|▍         | 11/233 [01:11<23:34,  6.37s/it]#015  5%|▌         | 12/233 [01:17<23:24,  6.35s/it]#015                                                #015#015  5%|▌         | 12/233 [01:17<23:24,  6.35s/it]#015  6%|▌         | 13/233 [01:23<23:15,  6.34s/it]#015                                                #015#015  6%|▌         | 13/233 [01:23<23:15,  6.34s/it]#015  6%|▌         | 14/233 [01:30<23:11,  6.35s/it]#015                                                #015#015  6%|▌         | 14/233 [01:30<23:11,  6.35s/it]#015  6%|▋         | 15/233 [01:36<23:12,  6.39s/it]#015                                                #015#015  6%|▋         | 15/233 [01:36<23:12,  6.39s/it]#015  7%|▋         | 16/233 [01:42<23:04,  6.38s/it]#015                                                #015#015  7%|▋         | 16/233 [01:42<23:04,  6.38s/it]#015  7%|▋         | 17/233 [01:49<22:55,  6.37s/it]#015                                                #015#015  7%|▋         | 17/233 [01:49<22:55,  6.37s/it]#015  8%|▊         | 18/233 [01:55<22:48,  6.36s/it]#015                                                #015#015  8%|▊         | 18/233 [01:55<22:48,  6.36s/it]#015  8%|▊         | 19/233 [02:01<22:36,  6.34s/it]#015                                                #015#015  8%|▊         | 19/233 [02:01<22:36,  6.34s/it]#015  9%|▊         | 20/233 [02:08<22:27,  6.33s/it]#015                                                #015#015  9%|▊         | 20/233 [02:08<22:27,  6.33s/it]#015  9%|▉         | 21/233 [02:14<22:20,  6.32s/it]#015                                                #015#015  9%|▉         | 21/233 [02:14<22:20,  6.32s/it]#015  9%|▉         | 22/233 [02:20<22:14,  6.33s/it]#015                                                #015#015  9%|▉         | 22/233 [02:20<22:14,  6.33s/it]#015 10%|▉         | 23/233 [02:27<22:18,  6.37s/it]#015                                                #015#015 10%|▉         | 23/233 [02:27<22:18,  6.37s/it]#015 10%|█         | 24/233 [02:33<22:13,  6.38s/it]#015                                                #015#015 10%|█         | 24/233 [02:33<22:13,  6.38s/it]#015 11%|█         | 25/233 [02:40<22:02,  6.36s/it]#015                                                #015#015 11%|█         | 25/233 [02:40<22:02,  6.36s/it]#015 11%|█         | 26/233 [02:46<21:55,  6.36s/it]#015                                                #015#015 11%|█         | 26/233 [02:46<21:55,  6.36s/it]#015 12%|█▏        | 27/233 [02:52<21:49,  6.36s/it]#015                                                #015#015 12%|█▏        | 27/233 [02:52<21:49,  6.36s/it]#015 12%|█▏        | 28/233 [02:59<21:42,  6.35s/it]#015                                                #015#015 12%|█▏        | 28/233 [02:59<21:42,  6.35s/it]#015 12%|█▏        | 29/233 [03:05<21:35,  6.35s/it]#015                                                #015#015 12%|█▏        | 29/233 [03:05<21:35,  6.35s/it]#015 13%|█▎        | 30/233 [03:11<21:27,  6.34s/it]#015                                                #015#015 13%|█▎        | 30/233 [03:11<21:27,  6.34s/it]#015 13%|█▎        | 31/233 [03:18<21:31,  6.39s/it]#015                                                #015#015 13%|█▎        | 31/233 [03:18<21:31,  6.39s/it]#015 14%|█▎        | 32/233 [03:24<21:21,  6.38s/it]#015                                                #015#015 14%|█▎        | 32/233 [03:24<21:21,  6.38s/it]#015 14%|█▍        | 33/233 [03:30<21:15,  6.38s/it]#015                                                #015#015 14%|█▍        | 33/233 [03:30<21:15,  6.38s/it]#015 15%|█▍        | 34/233 [03:37<21:05,  6.36s/it]#015                                                #015#015 15%|█▍        | 34/233 [03:37<21:05,  6.36s/it]#015 15%|█▌        | 35/233 [03:43<20:55,  6.34s/it]#015                                                #015#015 15%|█▌        | 35/233 [03:43<20:55,  6.34s/it]#015 15%|█▌        | 36/233 [03:49<20:44,  6.31s/it]#015                                                #015#015 15%|█▌        | 36/233 [03:49<20:44,  6.31s/it]#015 16%|█▌        | 37/233 [03:56<20:40,  6.33s/it]#015                                                #015#015 16%|█▌        | 37/233 [03:56<20:40,  6.33s/it]#015 16%|█▋        | 38/233 [04:02<20:42,  6.37s/it]#015                                                #015#015 16%|█▋        | 38/233 [04:02<20:42,  6.37s/it]#015 17%|█▋        | 39/233 [04:09<20:34,  6.37s/it]#015                                                #015#015 17%|█▋        | 39/233 [04:09<20:34,  6.37s/it]#015 17%|█▋        | 40/233 [04:15<20:26,  6.35s/it]#015                                                #015#015 17%|█▋        | 40/233 [04:15<20:26,  6.35s/it]#015 18%|█▊        | 41/233 [04:21<20:19,  6.35s/it]#015                                                #015#015 18%|█▊        | 41/233 [04:21<20:19,  6.35s/it]#015 18%|█▊        | 42/233 [04:28<20:15,  6.36s/it]#015                                                #015#015 18%|█▊        | 42/233 [04:28<20:15,  6.36s/it]#015 18%|█▊        | 43/233 [04:34<20:04,  6.34s/it]#015                                                #015#015 18%|█▊        | 43/233 [04:34<20:04,  6.34s/it]#015 19%|█▉        | 44/233 [04:40<19:57,  6.34s/it]#015                                                #015#015 19%|█▉        | 44/233 [04:40<19:57,  6.34s/it]#015 19%|█▉        | 45/233 [04:47<19:51,  6.34s/it]#015                                                #015#015 19%|█▉        | 45/233 [04:47<19:51,  6.34s/it]#015 20%|█▉        | 46/233 [04:53<19:52,  6.38s/it]#015                                                #015#015 20%|█▉        | 46/233 [04:53<19:52,  6.38s/it]#015 20%|██        | 47/233 [04:59<19:41,  6.35s/it]#015                                                #015#015 20%|██        | 47/233 [04:59<19:41,  6.35s/it]#015 21%|██        | 48/233 [05:06<19:32,  6.34s/it]#015                                                #015#015 21%|██        | 48/233 [05:06<19:32,  6.34s/it]#015 21%|██        | 49/233 [05:12<19:23,  6.33s/it]#015                                                #015#015 21%|██        | 49/233 [05:12<19:23,  6.33s/it]#015 21%|██▏       | 50/233 [05:18<19:18,  6.33s/it]#015                                                #015#015 21%|██▏       | 50/233 [05:18<19:18,  6.33s/it]#015 22%|██▏       | 51/233 [05:25<19:10,  6.32s/it]#015                                                #015#015 22%|██▏       | 51/233 [05:25<19:10,  6.32s/it]#015 22%|██▏       | 52/233 [05:31<19:05,  6.33s/it]#015                                                #015#015 22%|██▏       | 52/233 [05:31<19:05,  6.33s/it]#015 23%|██▎       | 53/233 [05:37<18:58,  6.32s/it]#015                                                #015#015 23%|██▎       | 53/233 [05:37<18:58,  6.32s/it]#015 23%|██▎       | 54/233 [05:44<18:58,  6.36s/it]#015                                                #015#015 23%|██▎       | 54/233 [05:44<18:58,  6.36s/it]#015 24%|██▎       | 55/233 [05:50<18:51,  6.36s/it]#015                                                #015#015 24%|██▎       | 55/233 [05:50<18:51,  6.36s/it]#015 24%|██▍       | 56/233 [05:56<18:44,  6.35s/it]#015                                                #015#015 24%|██▍       | 56/233 [05:56<18:44,  6.35s/it]#015 24%|██▍       | 57/233 [06:03<18:34,  6.33s/it]#015                                                #015#015 24%|██▍       | 57/233 [06:03<18:34,  6.33s/it]#015 25%|██▍       | 58/233 [06:09<18:26,  6.32s/it]#015                                                #015#015 25%|██▍       | 58/233 [06:09<18:26,  6.32s/it]#015 25%|██▌       | 59/233 [06:15<18:19,  6.32s/it]#015                                                #015#015 25%|██▌       | 59/233 [06:15<18:19,  6.32s/it]#015 26%|██▌       | 60/233 [06:22<18:14,  6.33s/it]#015                                                #015#015 26%|██▌       | 60/233 [06:22<18:14,  6.33s/it]#015 26%|██▌       | 61/233 [06:28<18:17,  6.38s/it]#015                                                #015#015 26%|██▌       | 61/233 [06:28<18:17,  6.38s/it]#015 27%|██▋       | 62/233 [06:34<18:09,  6.37s/it]#015                                                #015#015 27%|██▋       | 62/233 [06:34<18:09,  6.37s/it]#015 27%|██▋       | 63/233 [06:41<18:02,  6.37s/it]#015                                                #015#015 27%|██▋       | 63/233 [06:41<18:02,  6.37s/it]#015 27%|██▋       | 64/233 [06:47<17:55,  6.37s/it]#015                                                #015#015 27%|██▋       | 64/233 [06:47<17:55,  6.37s/it]#015 28%|██▊       | 65/233 [06:53<17:46,  6.35s/it]#015                                                #015#015 28%|██▊       | 65/233 [06:53<17:46,  6.35s/it]#015 28%|██▊       | 66/233 [07:00<17:40,  6.35s/it]#015                                                #015#015 28%|██▊       | 66/233 [07:00<17:40,  6.35s/it]#015 29%|██▉       | 67/233 [07:06<17:31,  6.34s/it]#015                                                #015#015 29%|██▉       | 67/233 [07:06<17:31,  6.34s/it]#015 29%|██▉       | 68/233 [07:12<17:24,  6.33s/it]#015                                                #015#015 29%|██▉       | 68/233 [07:12<17:24,  6.33s/it]#015 30%|██▉       | 69/233 [07:19<17:25,  6.37s/it]#015                                                #015#015 30%|██▉       | 69/233 [07:19<17:25,  6.37s/it]#015 30%|███       | 70/233 [07:25<17:16,  6.36s/it]#015                                                #015#015 30%|███       | 70/233 [07:25<17:16,  6.36s/it]#015 30%|███       | 71/233 [07:32<17:10,  6.36s/it]#015                                                #015#015 30%|███       | 71/233 [07:32<17:10,  6.36s/it]#015 31%|███       | 72/233 [07:38<17:04,  6.36s/it]#015                                                #015#015 31%|███       | 72/233 [07:38<17:04,  6.36s/it]#015 31%|███▏      | 73/233 [07:44<16:55,  6.35s/it]#015                                                #015#015 31%|███▏      | 73/233 [07:44<16:55,  6.35s/it]#015 32%|███▏      | 74/233 [07:51<16:49,  6.35s/it]#015                                                #015#015 32%|███▏      | 74/233 [07:51<16:49,  6.35s/it]#015 32%|███▏      | 75/233 [07:57<16:42,  6.34s/it]#015                                                #015#015 32%|███▏      | 75/233 [07:57<16:42,  6.34s/it]#015 33%|███▎      | 76/233 [08:03<16:35,  6.34s/it]#015                                                #015#015 33%|███▎      | 76/233 [08:03<16:35,  6.34s/it]#015 33%|███▎      | 77/233 [08:10<16:35,  6.38s/it]#015                                                #015#015 33%|███▎      | 77/233 [08:10<16:35,  6.38s/it]#015 33%|███▎      | 78/233 [08:16<16:26,  6.36s/it]#015                                                #015#015 33%|███▎      | 78/233 [08:16<16:26,  6.36s/it]#015 34%|███▍      | 79/233 [08:22<16:18,  6.35s/it]#015                                                #015#015 34%|███▍      | 79/233 [08:22<16:18,  6.35s/it]#015 34%|███▍      | 80/233 [08:29<16:13,  6.36s/it]#015                                                #015#015 34%|███▍      | 80/233 [08:29<16:13,  6.36s/it]#015 35%|███▍      | 81/233 [08:35<16:06,  6.36s/it]#015                                                #015#015 35%|███▍      | 81/233 [08:35<16:06,  6.36s/it]#015 35%|███▌      | 82/233 [08:41<15:59,  6.35s/it]#015                                                #015#015 35%|███▌      | 82/233 [08:41<15:59,  6.35s/it]#015 36%|███▌      | 83/233 [08:48<15:51,  6.34s/it]#015                                                #015#015 36%|███▌      | 83/233 [08:48<15:51,  6.34s/it]#015 36%|███▌      | 84/233 [08:54<15:50,  6.38s/it]#015                                                #015#015 36%|███▌      | 84/233 [08:54<15:50,  6.38s/it]#015 36%|███▋      | 85/233 [09:01<15:41,  6.36s/it]#015                                                #015#015 36%|███▋      | 85/233 [09:01<15:41,  6.36s/it]#015 37%|███▋      | 86/233 [09:07<15:33,  6.35s/it]#015                                                #015#015 37%|███▋      | 86/233 [09:07<15:33,  6.35s/it]#015 37%|███▋      | 87/233 [09:13<15:26,  6.35s/it]#015                                                #015#015 37%|███▋      | 87/233 [09:13<15:26,  6.35s/it]#015 38%|███▊      | 88/233 [09:20<15:18,  6.33s/it]#015                                                #015#015 38%|███▊      | 88/233 [09:20<15:18,  6.33s/it]#015 38%|███▊      | 89/233 [09:26<15:12,  6.34s/it]#015                                                #015#015 38%|███▊      | 89/233 [09:26<15:12,  6.34s/it]#015 39%|███▊      | 90/233 [09:32<15:06,  6.34s/it]#015                                                #015#015 39%|███▊      | 90/233 [09:32<15:06,  6.34s/it]#015 39%|███▉      | 91/233 [09:39<14:58,  6.33s/it]#015                                                #015#015 39%|███▉      | 91/233 [09:39<14:58,  6.33s/it]#015 39%|███▉      | 92/233 [09:45<14:57,  6.36s/it]#015                                                #015#015 39%|███▉      | 92/233 [09:45<14:57,  6.36s/it]#015 40%|███▉      | 93/233 [09:51<14:48,  6.35s/it]#015                                                #015#015 40%|███▉      | 93/233 [09:51<14:48,  6.35s/it]#015 40%|████      | 94/233 [09:58<14:41,  6.34s/it]#015                                                #015#015 40%|████      | 94/233 [09:58<14:41,  6.34s/it]#015 41%|████      | 95/233 [10:04<14:35,  6.34s/it]#015                                                #015#015 41%|████      | 95/233 [10:04<14:35,  6.34s/it]#015 41%|████      | 96/233 [10:10<14:29,  6.34s/it]#015                                                #015#015 41%|████      | 96/233 [10:10<14:29,  6.34s/it]#015 42%|████▏     | 97/233 [10:17<14:22,  6.34s/it]#015                                                #015#015 42%|████▏     | 97/233 [10:17<14:22,  6.34s/it]#015 42%|████▏     | 98/233 [10:23<14:14,  6.33s/it]#015                                                #015#015 42%|████▏     | 98/233 [10:23<14:14,  6.33s/it]#015 42%|████▏     | 99/233 [10:29<14:09,  6.34s/it]#015                                                #015#015 42%|████▏     | 99/233 [10:29<14:09,  6.34s/it]#015 43%|████▎     | 100/233 [10:36<14:08,  6.38s/it]#015                                                 #015#015 43%|████▎     | 100/233 [10:36<14:08,  6.38s/it]#015 43%|████▎     | 101/233 [10:42<13:59,  6.36s/it]#015                                                 #015#015 43%|████▎     | 101/233 [10:42<13:59,  6.36s/it]#015 44%|████▍     | 102/233 [10:48<13:51,  6.35s/it]#015                                                 #015#015 44%|████▍     | 102/233 [10:48<13:51,  6.35s/it]#015 44%|████▍     | 103/233 [10:55<13:44,  6.34s/it]#015                                                 #015#015 44%|████▍     | 103/233 [10:55<13:44,  6.34s/it]#015 45%|████▍     | 104/233 [11:01<13:38,  6.34s/it]#015              \u001b[0m\n",
      "\u001b[34mStep 105: Loss = 0.9650\u001b[0m\n",
      "\u001b[34m{'loss': 0.9258, 'grad_norm': 1.1044200658798218, 'learning_rate': 0.0005663716814159292, 'epoch': 0.45}\u001b[0m\n",
      "\u001b[34mStep 106: Loss = 0.9258\u001b[0m\n",
      "\u001b[34m{'loss': 0.9928, 'grad_norm': 1.0502740144729614, 'learning_rate': 0.0005619469026548672, 'epoch': 0.45}\u001b[0m\n",
      "\u001b[34mStep 107: Loss = 0.9928\u001b[0m\n",
      "\u001b[34m{'loss': 0.9741, 'grad_norm': 1.001561164855957, 'learning_rate': 0.0005575221238938053, 'epoch': 0.46}\u001b[0m\n",
      "\u001b[34mStep 108: Loss = 0.9741\u001b[0m\n",
      "\u001b[34m{'loss': 0.9901, 'grad_norm': 1.086859941482544, 'learning_rate': 0.0005530973451327434, 'epoch': 0.46}\u001b[0m\n",
      "\u001b[34mStep 109: Loss = 0.9901\u001b[0m\n",
      "\u001b[34m{'loss': 1.0129, 'grad_norm': 0.99544757604599, 'learning_rate': 0.0005486725663716814, 'epoch': 0.47}\u001b[0m\n",
      "\u001b[34mStep 110: Loss = 1.0129\u001b[0m\n",
      "\u001b[34m{'loss': 1.0026, 'grad_norm': 1.0647997856140137, 'learning_rate': 0.0005442477876106194, 'epoch': 0.47}\u001b[0m\n",
      "\u001b[34mStep 111: Loss = 1.0026\u001b[0m\n",
      "\u001b[34m{'loss': 0.9056, 'grad_norm': 1.0614674091339111, 'learning_rate': 0.0005398230088495575, 'epoch': 0.48}\u001b[0m\n",
      "\u001b[34mStep 112: Loss = 0.9056\u001b[0m\n",
      "\u001b[34m{'loss': 0.984, 'grad_norm': 0.9176657795906067, 'learning_rate': 0.0005353982300884956, 'epoch': 0.48}\u001b[0m\n",
      "\u001b[34mStep 113: Loss = 0.9840\u001b[0m\n",
      "\u001b[34m{'loss': 0.983, 'grad_norm': 0.9115254878997803, 'learning_rate': 0.0005309734513274337, 'epoch': 0.48}\u001b[0m\n",
      "\u001b[34mStep 114: Loss = 0.9830\u001b[0m\n",
      "\u001b[34m{'loss': 0.9515, 'grad_norm': 0.9010834097862244, 'learning_rate': 0.0005265486725663717, 'epoch': 0.49}\u001b[0m\n",
      "\u001b[34mStep 115: Loss = 0.9515\u001b[0m\n",
      "\u001b[34m{'loss': 0.9149, 'grad_norm': 0.9831101894378662, 'learning_rate': 0.0005221238938053098, 'epoch': 0.49}\u001b[0m\n",
      "\u001b[34mStep 116: Loss = 0.9149\u001b[0m\n",
      "\u001b[34m{'loss': 0.8632, 'grad_norm': 1.0248115062713623, 'learning_rate': 0.0005176991150442478, 'epoch': 0.5}\u001b[0m\n",
      "\u001b[34mStep 117: Loss = 0.8632\u001b[0m\n",
      "\u001b[34m{'loss': 0.9178, 'grad_norm': 0.9808615446090698, 'learning_rate': 0.0005132743362831858, 'epoch': 0.5}\u001b[0m\n",
      "\u001b[34mStep 118: Loss = 0.9178\u001b[0m\n",
      "\u001b[34m{'loss': 0.8875, 'grad_norm': 0.9353005290031433, 'learning_rate': 0.0005088495575221239, 'epoch': 0.51}\u001b[0m\n",
      "\u001b[34mStep 119: Loss = 0.8875\u001b[0m\n",
      "\u001b[34m{'loss': 0.9741, 'grad_norm': 0.8681107759475708, 'learning_rate': 0.000504424778761062, 'epoch': 0.51}\u001b[0m\n",
      "\u001b[34mStep 120: Loss = 0.9741\u001b[0m\n",
      "\u001b[34m{'loss': 0.9906, 'grad_norm': 0.8457785844802856, 'learning_rate': 0.0005, 'epoch': 0.52}\u001b[0m\n",
      "\u001b[34mStep 121: Loss = 0.9906\u001b[0m\n",
      "\u001b[34m{'loss': 0.9378, 'grad_norm': 0.8549975752830505, 'learning_rate': 0.000495575221238938, 'epoch': 0.52}\u001b[0m\n",
      "\u001b[34mStep 122: Loss = 0.9378\u001b[0m\n",
      "\u001b[34m{'loss': 0.8872, 'grad_norm': 0.8217984437942505, 'learning_rate': 0.0004911504424778762, 'epoch': 0.52}\u001b[0m\n",
      "\u001b[34mStep 123: Loss = 0.8872\u001b[0m\n",
      "\u001b[34m{'loss': 0.9005, 'grad_norm': 0.947526752948761, 'learning_rate': 0.0004867256637168142, 'epoch': 0.53}\u001b[0m\n",
      "\u001b[34mStep 124: Loss = 0.9005\u001b[0m\n",
      "\u001b[34m{'loss': 0.9089, 'grad_norm': 0.817709743976593, 'learning_rate': 0.0004823008849557522, 'epoch': 0.53}\u001b[0m\n",
      "\u001b[34mStep 125: Loss = 0.9089\u001b[0m\n",
      "\u001b[34m{'loss': 0.8833, 'grad_norm': 0.8755784630775452, 'learning_rate': 0.0004778761061946903, 'epoch': 0.54}\u001b[0m\n",
      "\u001b[34mStep 126: Loss = 0.8833\u001b[0m\n",
      "\u001b[34m{'loss': 0.9023, 'grad_norm': 0.8673571944236755, 'learning_rate': 0.00047345132743362834, 'epoch': 0.54}\u001b[0m\n",
      "\u001b[34mStep 127: Loss = 0.9023\u001b[0m\n",
      "\u001b[34m{'loss': 0.9096, 'grad_norm': 0.8685963749885559, 'learning_rate': 0.0004690265486725664, 'epoch': 0.55}\u001b[0m\n",
      "\u001b[34mStep 128: Loss = 0.9096\u001b[0m\n",
      "\u001b[34m{'loss': 0.9368, 'grad_norm': 0.8365863561630249, 'learning_rate': 0.00046460176991150443, 'epoch': 0.55}\u001b[0m\n",
      "\u001b[34mStep 129: Loss = 0.9368\u001b[0m\n",
      "\u001b[34m{'loss': 0.9749, 'grad_norm': 0.8278864026069641, 'learning_rate': 0.0004601769911504425, 'epoch': 0.55}\u001b[0m\n",
      "\u001b[34mStep 130: Loss = 0.9749\u001b[0m\n",
      "\u001b[34m{'loss': 0.8734, 'grad_norm': 0.8657603859901428, 'learning_rate': 0.0004557522123893805, 'epoch': 0.56}\u001b[0m\n",
      "\u001b[34mStep 131: Loss = 0.8734\u001b[0m\n",
      "\u001b[34m{'loss': 0.858, 'grad_norm': 0.8965367078781128, 'learning_rate': 0.0004513274336283186, 'epoch': 0.56}\u001b[0m\n",
      "\u001b[34mStep 132: Loss = 0.8580\u001b[0m\n",
      "\u001b[34m{'loss': 0.9701, 'grad_norm': 0.8369291424751282, 'learning_rate': 0.0004469026548672566, 'epoch': 0.57}\u001b[0m\n",
      "\u001b[34mStep 133: Loss = 0.9701\u001b[0m\n",
      "\u001b[34m{'loss': 0.8992, 'grad_norm': 0.8021364808082581, 'learning_rate': 0.00044247787610619474, 'epoch': 0.57}\u001b[0m\n",
      "\u001b[34mStep 134: Loss = 0.8992\u001b[0m\n",
      "\u001b[34m{'loss': 0.8255, 'grad_norm': 0.8529418706893921, 'learning_rate': 0.00043805309734513276, 'epoch': 0.58}\u001b[0m\n",
      "\u001b[34mStep 135: Loss = 0.8255\u001b[0m\n",
      "\u001b[34m{'loss': 0.8672, 'grad_norm': 0.9010443091392517, 'learning_rate': 0.00043362831858407083, 'epoch': 0.58}\u001b[0m\n",
      "\u001b[34mStep 136: Loss = 0.8672\u001b[0m\n",
      "\u001b[34m{'loss': 0.8825, 'grad_norm': 0.7646540403366089, 'learning_rate': 0.00042920353982300885, 'epoch': 0.58}\u001b[0m\n",
      "\u001b[34mStep 137: Loss = 0.8825\u001b[0m\n",
      "\u001b[34m{'loss': 0.8891, 'grad_norm': 1.012496829032898, 'learning_rate': 0.0004247787610619469, 'epoch': 0.59}\u001b[0m\n",
      "\u001b[34mStep 138: Loss = 0.8891\u001b[0m\n",
      "\u001b[34m{'loss': 0.863, 'grad_norm': 0.8152198195457458, 'learning_rate': 0.00042035398230088494, 'epoch': 0.59}\u001b[0m\n",
      "\u001b[34mStep 139: Loss = 0.8630\u001b[0m\n",
      "\u001b[34m{'loss': 0.8862, 'grad_norm': 1.0258309841156006, 'learning_rate': 0.000415929203539823, 'epoch': 0.6}\u001b[0m\n",
      "\u001b[34mStep 140: Loss = 0.8862\u001b[0m\n",
      "\u001b[34m{'loss': 0.9099, 'grad_norm': 0.8385304808616638, 'learning_rate': 0.00041150442477876103, 'epoch': 0.6}\u001b[0m\n",
      "\u001b[34mStep 141: Loss = 0.9099\u001b[0m\n",
      "\u001b[34m{'loss': 0.8469, 'grad_norm': 0.9119709134101868, 'learning_rate': 0.00040707964601769916, 'epoch': 0.61}\u001b[0m\n",
      "\u001b[34mStep 142: Loss = 0.8469\u001b[0m\n",
      "\u001b[34m{'loss': 0.8407, 'grad_norm': 0.8937882781028748, 'learning_rate': 0.0004026548672566372, 'epoch': 0.61}\u001b[0m\n",
      "\u001b[34mStep 143: Loss = 0.8407\u001b[0m\n",
      "\u001b[34m{'loss': 0.8837, 'grad_norm': 0.8991223573684692, 'learning_rate': 0.00039823008849557525, 'epoch': 0.61}\u001b[0m\n",
      "\u001b[34mStep 144: Loss = 0.8837\u001b[0m\n",
      "\u001b[34m{'loss': 0.8713, 'grad_norm': 0.8138335943222046, 'learning_rate': 0.00039380530973451327, 'epoch': 0.62}\u001b[0m\n",
      "\u001b[34mStep 145: Loss = 0.8713\u001b[0m\n",
      "\u001b[34m{'loss': 0.8815, 'grad_norm': 0.7721114754676819, 'learning_rate': 0.00038938053097345134, 'epoch': 0.62}\u001b[0m\n",
      "\u001b[34mStep 146: Loss = 0.8815\u001b[0m\n",
      "\u001b[34m{'loss': 0.8348, 'grad_norm': 0.8964329957962036, 'learning_rate': 0.00038495575221238936, 'epoch': 0.63}\u001b[0m\n",
      "\u001b[34mStep 147: Loss = 0.8348\u001b[0m\n",
      "\u001b[34m{'loss': 0.8901, 'grad_norm': 0.824778139591217, 'learning_rate': 0.00038053097345132743, 'epoch': 0.63}\u001b[0m\n",
      "\u001b[34mStep 148: Loss = 0.8901\u001b[0m\n",
      "\u001b[34m{'loss': 0.8119, 'grad_norm': 0.8837280869483948, 'learning_rate': 0.00037610619469026545, 'epoch': 0.64}\u001b[0m\n",
      "\u001b[34mStep 149: Loss = 0.8119\u001b[0m\n",
      "\u001b[34m{'loss': 0.885, 'grad_norm': 0.8630686402320862, 'learning_rate': 0.0003716814159292036, 'epoch': 0.64}\u001b[0m\n",
      "\u001b[34mStep 150: Loss = 0.8850\u001b[0m\n",
      "\u001b[34m{'loss': 0.8518, 'grad_norm': 0.8433468341827393, 'learning_rate': 0.0003672566371681416, 'epoch': 0.64}\u001b[0m\n",
      "\u001b[34mStep 151: Loss = 0.8518\u001b[0m\n",
      "\u001b[34m{'loss': 0.8708, 'grad_norm': 0.799811840057373, 'learning_rate': 0.00036283185840707967, 'epoch': 0.65}\u001b[0m\n",
      "\u001b[34mStep 152: Loss = 0.8708\u001b[0m\n",
      "\u001b[34m{'loss': 0.8134, 'grad_norm': 0.8824604153633118, 'learning_rate': 0.0003584070796460177, 'epoch': 0.65}\u001b[0m\n",
      "\u001b[34mStep 153: Loss = 0.8134\u001b[0m\n",
      "\u001b[34m{'loss': 0.8594, 'grad_norm': 0.8749393224716187, 'learning_rate': 0.00035398230088495576, 'epoch': 0.66}\u001b[0m\n",
      "\u001b[34mStep 154: Loss = 0.8594\u001b[0m\n",
      "\u001b[34m{'loss': 0.9138, 'grad_norm': 0.8498300313949585, 'learning_rate': 0.0003495575221238938, 'epoch': 0.66}\u001b[0m\n",
      "\u001b[34mStep 155: Loss = 0.9138\u001b[0m\n",
      "\u001b[34m{'loss': 0.9149, 'grad_norm': 0.8080991506576538, 'learning_rate': 0.00034513274336283185, 'epoch': 0.67}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train_input = 's3://secludy-public-listing/costco_emails_formatted.jsonl'\n",
    "\n",
    "estimator.fit({'training': train_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae3b53b-7c42-45d2-91d5-8e51e758c303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
